---
title: "ACrep_Results.Rmd"
author: "Hannah Moshontz, running Erin Buchanan's Analysis Script"
date: "Last Updated `r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

## Purpose

This script generates text for the results section of the ACREP / PSA004 Stage 2 RRR. It also runs the analysis .Rmd.

# Run the analysis script

```{r, child = '../05_Analysis/ACrep_Analysis_V2.Rmd', include = FALSE, results = FALSE}
```

# Set up 

```{r packages}
library(janitor)
library(stringr)
library(kableExtra)
library(countrycode)
library(ISOcodes)
#library(tidylog)
library(naniar) # to evaluate missing data
library(broom.mixed) # for nicely presented results
```

```{r functions}

#a function to make names in the tidy model objects less confusing
#used to prep results tables
clean_variable_names <- function(tidy_model_obj){
  
  tidy_model_obj %>% 
    mutate(group = str_replace(group, "Person.*", "site"),
           group = str_replace(group, "id:vignette","participant")) %>% 
    mutate(term = str_replace(term, "compYes", "compensation"),
           term = str_replace(term, "gender2male", "gender"))
  
}

```


# EDA on the analysis set


A few notes about variables:
- Person is a unique lab identifier (identifies PI)
- lab_id is a not a unique lab identifier, but rather identifies the undergraduate PI
(and some of these undergraduate PIs were students with the same lab PI)
- lab_country is the variable we are using to identify country/region
- UN_Region groups lab country into larger regions
- source identifies the method of data collection
- id uniquely identifies each participant by concatenating the source (qualtrics vs socscisurvey),
undergraduate PI (lab_id), and the unique identifier (case, which was of a different format depending on source)
- variables ending in valid are logical and identify valid cases (in the "final_long" dataset, there will not be variance)
- variables ending in order indicate the order in which vignettes or condition were presented (varies by participant),
or the order in which binary DVs were presented (for socscisurvey, this varies by person within lab such that people 
were presented with "normal" (*not sure what direction this is*) or "swapped", but for Qualtrics, this was randomized 
within person and so is coded as "mixed" and and we do not have more detailed information about order in the final dataset. also one lab didn't properly randomize.)
- 2104 N are missing age. are these likely test observations? and so this exclusion and over 100 were a way to try to catch the test observations.

```{r UN_Region}
full_long %>% filter(is.na(UN_Region)) %>% tabyl(lab_id)
```
Information that came from lab_sheet (ultimately the source was a google doc) is not accurate and doesn't contain information about qualtrics labs. This is a problem.

```{r years of education}
final_long$education[which(final_long$education <10)] %>% 
  hist()
```

`r length(final_long$education[which(final_long$education <10)])` people report what amounts to less than a high school diploma. `r final_long$education[which(final_long$education <2)]` people said they had one year of education. This warrants observation in the manuscript.

# Method


```{r}

#labs that applied
n_labs_applied <- 69
n_labs_rejected <- (69-37)
n_labs_failed <- 30
n_labs_finished_crep <- 22
# sources: https://docs.google.com/spreadsheets/d/1Y4ZFB0AZQMhjVwGP-aA9eEC2CWKUUq5LdJu7wZLAdQ8/edit#gid=575778621
# https://docs.google.com/spreadsheets/d/1Y4ZFB0AZQMhjVwGP-aA9eEC2CWKUUq5LdJu7wZLAdQ8/edit#gid=1889366473

#create table content

#save teams per site
teams_per_site <- final_long %>% 
  group_by(Person, lab_id) %>% group_by(Person, lab_id) %>% count() %>% 
  group_by(Person) %>% count() %>%
  rename(n_student_teams = n) %>% 
  ungroup() %>% 
  glimpse()

#save full n per site
full_data_n_per_site <- full_long %>% 
  group_by(Person, id) %>% count() %>% 
  group_by(Person) %>% count() %>% 
  rename(full_data_n = n) %>% 
  ungroup() %>% 
  glimpse()

#save final n per site
final_data_n_per_site <- final_long %>% 
  group_by(Person, id) %>% count() %>% 
  group_by(Person) %>% count() %>% 
  rename(final_data_n = n) %>% 
  ungroup() %>% 
  glimpse()

#check assumption that each site had one data collection source...
#error out if any site contributed data from both Qualtrics and SSS
if (full_long %>% 
  group_by(Person, source) %>% count() %>% 
  group_by(Person) %>% count() %>% 
  filter(n > 1) %>% 
  nrow() %>% .[1] != 0) STOP

#save survey platform info
platform <- full_long %>% 
  group_by(Person) %>% 
  summarize(survey_platform = first(source)) %>%
  ungroup() %>% 
  glimpse()

#save world region info
full_long %>% 
  group_by(Person)

#check assumption that each site had one compensation type...
#something is fishy
#FIX: Need to check all comp information in lab_sheet and it's source gsheet -- people in the same data site have different values
#these values should reflect the compensation that was in people's
#IRB approvals
multiple_compensation <- lab_sheet %>% 
   group_by(Person, Compensation) %>% count() %>% 
   group_by(Person) %>% count() %>% 
   filter(n > 1) %>% pull(Person)

#FIX:exporting summary of issue
lab_sheet %>% 
  filter(Person %in% multiple_compensation) %>% 
  select(lab_code, Person, Compensation, comp) 
  #write.csv("compensation_discrepancies.csv")

#save compensation information 
lab_sheet %>% 
  select(Person, Compensation) %>% 
  group_by(Person) %>% 
  count()

#FIX: Need to do the same for the remaining columns:
#(this is the table we hope to fill with this code https://docs.google.com/spreadsheets/d/1zjnaAMd8EbGsgY5PPAWwoZg7Fkm5P-0NO-amhmHqDpg/edit#gid=0)
# UN_Region
# Method variations or extension notes
# Whether any data were collected in groups
# Whether any data were collected in person
# Whether community samples were used / what the sampled population is

left_join(teams_per_site, full_data_n_per_site, by = "Person") %>% 
  left_join(final_data_n_per_site, by = "Person") %>% 
  left_join(platform, by = "Person") %>% 
  #FIX: join checked UN region
  #FIX: join checked compensation method in the IRB
  #FIX: join checked methods variations or extension notes
  #FIX: join checked sampled population (e.g., community, subject pool)
  #FIX: join checked grouped data collection info, even if all zeros
  #FIX: join whether any data were collected in person
arrange(-final_data_n) %>% 
  mutate(site_id = row_number()) %>% 
  select(site_id, everything()) %>% 
  clean_names("sentence") %>% 
  #FIX: delete next line once we have the data
  mutate(`UN Region` = 'check',
         `Compensation method` = 'check',
         `Method variations` = 'check',
         `Sampled population` = 'check',
         `Group data collection` = 'check',
         `In person data collection` = 'check') %>% 
  kable(caption = "Data Collection Site Information") %>% 
  kable_styling()
```


In the approved protocol, sections of the manuscript relevant to understanding the study method included detailed descriptions of the study's logistics, including the recruitment and approval of collaborators who would collect data. This section has been restructured to more closely resemble a typical study method description, including relevant information about the study's logisitics. The text from the approved protocol has been updated and moved to Appendix X.

## Participants

This project was designed to be a training and learning experience for undergraduate students. It was conceived of and led by the Collaborative Replications and Education Project (CREP; Wagge et al., cite) in concert with the Psychological Science Accelerator (PSA; Moshontz et al., 2019). For the undergraduate students who served the role of researcher in this study, the project involved collecting data and completing a series of tasks with pedagogical value, like independetly designing an analysis plan, completing a preregistration, independently executing analyses, and posting the study materials, data, and results summaries in a central repository. Each student-led team submitted a protocol for review to a CREP reviewer. Teams could not contribute to data collection until the protocol was approved (for more information about this process, see Appendix X).

For the present article and analyses, data are structured such that observations are nested within data collection sites. At some sites, there were multiple student-led teams who completed the project. Because observations collected by different teams are organized within a single data collection site, counts of student-led teams sometimes differ from counts of data collection sites. Further, some teams that were approved to collect data did not contribute data to this project, either because they did not collect any data (e.g., due to campus closures during the Covid-19 pandemic) or because data were collected in a way that rendered them unsuable for analyses (e.g., vignettes were not appropriately randomized). For a summary of student-led team and data collection site information, see Appendix X.



```{r}
#create dataset for demographics 
final_demographics <- final_long %>% 
  group_by(id) %>%
  slice(1) %>% 
  ungroup() %>% 
  select(id, 
         source,
         contains("exclusion"),
         contains("nonsense"),
         purpose,
         previous,
         survey_lang,
         turk,
         language,
         lab_id, 
         Person,
         lab_country,
         country,
         UN_Region,
         gender, 
         gender_other,
         starts_with("ethn_"),
         education,
         education_level,
         starts_with("comp"),
         birth_country,
         case,
         age)

full_demographics <- full_long %>% 
  group_by(id) %>%
  slice(1) %>% 
  ungroup() %>% 
  select(id, 
         source,
         contains("exclusion"),
         contains("nonsense"),
         purpose,
         previous,
         survey_lang,
         turk,
         language,
         lab_id, 
         Person,
         lab_country,
         country,
         UN_Region,
         gender, 
         gender_other,
         starts_with("ethn_"),
         education,
         education_level,
         starts_with("comp"),
         birth_country,
         case,
         age)

#error out if count doesn't match
if (length(unique(final_long$id)) != nrow(final_demographics)) STOP

```

In total, `r n_labs_applied` teams led by undergraduate students signed up to collect data for this project.  Of the teams that originally signed up, `r n_labs_rejected` either did not submit protocols for review or submitted protocols but did not complete required revisions. In total, `r n_labs_finished_crep` teams completed the entire project, including the purely pedagogical tasks. Some teams collected data but did not complete the project. Prior to exclusions, `r length(unique(full_demographics$Person))` unique data collection sites contributed data to the project. Data collection sites were located in `r length(unique(full_long$lab_country))` countries spanning world regions (i.e., `r count(group_by(full_long, UN_Region)) %>% drop_na() %>% arrange(-n) %>% pull(UN_Region) %>% paste(collapse = ", ")`). See Table X for a summary of student-led teams, and Table X for a summary of data collection sites.

Of the `r nrow(full_demographics)` participants who completed the survey, data from `r round((nrow(full_demographics) - nrow(final_demographics))/nrow(full_demographics), 3)*100`% (_n_ = `r (nrow(full_demographics) - nrow(final_demographics))`) of people were excluded.

Data were excluded for the following reasons (applied in the order listed):
(1) the participant did not provide an age, listed an age greater than or equal to 100, or was not the majority age of their country or older,  operationalized as at least 18 in all countries except Slovakia, where the age of consent is 19, and United Arab Emirates, where the age of consent is 21 (_n_ = `r nrow(filter(full_demographics, age_exclusion))`);
(2) the participant had taken part in a previous version of this study or in another contributors' replication of the same study (_n_ = `r nrow(filter(full_demographics, previous_exclusion))`);
(3) the participant failed to answer all three of the vignette comprehension questions correctly (_n_ = `r nrow(filter(full_demographics, studyans_exclusion))`; e.g., did not correctly identify what Darrel was looking at);
(4) the participant correctly and explicitly articulated knowledge of the specific hypotheses or specific conditions of this study when asked what they thought the study hypothesis was (_n_ = `r nrow(filter(full_demographics, purpose_exclusion))`);
(5) the participant reported their understanding of the language the survey was written in as "not well" or "not well at all" (_n_ = `r nrow(filter(full_demographics, lang_exclusion))`); see Vickstrom, Shin, Collazo, & Bauman, 2015).

Many excluded observations met multiple criteria. Exclusion criteria was not evaluated when the response was missing, except for age.

```{r}
exclusions %>% 
  kable(caption = "Multiway Table of All Exclusions") %>% 
  kable_styling()

#Note: There are many NA in exclusion criteria because we didn't evaluate folks that were excluded for previous criteria
```


Evaluating criteria 2 and 4 required making subjective judgements about open-ended responses. Each non-missing observation was evaluated by three people who spoke the langauge. These three raters did not translate responses, but instead directly evaluated responses with respect to the exclusion criteria (see the Appendix for the instructions given to raters and information about how ratings were combined). Ratings themselves are available at osf.io/gs29c. Responses marked as identified test cases (e.g., "TEST") were excluded. Responses that were not coherent were labeled, but not excluded, and some observations in the final data were not coherent (_n_ study purpose = `r nrow(filter(final_demographics, purpose_nonsense))`; _n_ previously participated = `r nrow(filter(final_demographics, previous_nonsense))`). Responses that were missing were not evaluated by raters, but no observations in the final dataset were missing evalutions (_n_ study purpose = `r nrow(filter(final_demographics, is.na(purpose_exclusion)))`; _n_ previously participated = `r nrow(filter(final_demographics, is.na(previous_exclusion)))`). 

All of these exclusions were preregistered with one exception. We did not pregister the exclusion of people over the age of 100, which resulted in the excusion of data from `r nrow(filter(full_demographics, !(age < 100)))` people. The age exclusion was made first, and captured many observations in the data that appeared to be invalid test responses. Data collection sites were not given instructions about avoiding or clearly identifying test responses. At many data collection sites, the students and other researchers executing the study tested their survey link multiple times (e.g., as inferred by responses to open-ended questions marked "test"). The exclusion of people over the age of 100 likely captured many invalid test responses. 

In the analysis sample (i.e., following exclusions), participants were `r nrow(final_demographics)` adults recruited to participate by student researchers at `r length(unique(final_long$Person))` data collection sites in `r length(unique(final_long$lab_country))` countries spanning world regions (i.e., `r count(group_by(final_long, UN_Region)) %>% drop_na() %>% arrange(-n) %>% pull(UN_Region) %>% paste(collapse = ", ")`). Data collection sites contributed an average of `r final_demographics %>% group_by(Person) %>% count() %>% pull(n) %>% mean() %>% round(2)` participants to the anlaysis sample (min = `r final_demographics %>% group_by(Person) %>% count() %>% pull(n) %>% min()`, max = `r final_demographics %>% group_by(Person) %>% count() %>% pull(n) %>% max()`). See Table X for a summary of participants' age, years of education, and ethnic/racial identity.

Participation details, like compensation and the sampled population, varied by data collection site, as summarized in Table X. In the approved protocol, we planned to collect all data using a single SocSciSurvey survey programmed to accomodate lab-specific variations. However, some used Qualtrics surveys that student researchers programmed themselves. Most data collection sites used the central SocSciSurvey survey.

```{r}
final_demographics %>% 
  select(age, education) %>% 
  describe() %>% 
  .[1:2,c(2,3,4,8,9)] %>% 
  kable(digits = 2) %>% 
  kable_styling()
```

In the approved proposal, we planned to measure participants' racial and ethnic identities using an open-ended response. For reasons that were not documented, racial and ethnic identity was measured using non-exclusive cateogories with an open-ended fill-in option. Student research teams designed different response options tailored to their geographic region (see all variations in Appendixal Table X). All data collection sites allowed people to select multiple racial and ethnic identities, and all asked whether participants identified as White (either "White/European", "White / European descent", or "European descent"). In the final sample, `r round(nrow(filter(final_demographics, ethn_wh == TRUE))/nrow(final_demographics)*100, 2)`% (_n_ = `r nrow(filter(final_demographics, ethn_wh == TRUE))`) identified as White.


```{r}
final_demographics %>% 
  select(comp, turk, source) %>% 
  mutate(source = as.factor(source)) %>% 
  mutate(across(.cols = everything(), ~as.numeric(.x))) %>% 
  mutate(comp = comp - 1,
         `Took the centralized survey` = source - 1) %>%  #adjusting numeric values so 0 is no and 1 is yes
  select(-source) %>% 
  rename(`Recruited through Mturk` = turk,
         `Compensated for participation` = comp) %>% 
  describe() %>% 
  .[,c(2,3,4,8,9)] %>% 
  mutate(count = n*mean,
         percent = count/n*100) %>% 
  select(count, percent) %>% 
  kable(digits = 2, caption = "Number and Percent of Participants by Data Collection Context Variables in Analysis Data (Total N = 2957)") %>% 
  kable_styling()

```


```{r}
final_demographics %>% 
  mutate(lab_country_full = countrycode(lab_country, "iso3c", "country.name.en")) %>% 
  tabyl(lab_country_full) %>% 
  arrange(-n) %>% 
  kable(digits = 2, caption = "Number and Percent of Participants by Country in Analysis Data") %>% 
  kable_styling()
```

```{r}
survey_lang_table <- final_demographics %>%
  mutate(survey_lang = str_replace_all(survey_lang, "prt", "por"),
         survey_lang = str_replace_all(survey_lang, "zho", "chi")) %>% 
  tabyl(survey_lang) %>% 
  arrange(-n)

for (i in 1:length(survey_lang_table$survey_lang)) {
  
  survey_lang_table$survey_lang[i] <- ISO_639_2$Name[ISO_639_2$Alpha_3_B == survey_lang_table$survey_lang[i]]
  
}

survey_lang_table %>% 
  mutate(survey_lang = str_replace_all(survey_lang, "Greek, Modern \\(1453\\-\\)", "Greek"),
         survey_lang = str_replace_all(survey_lang, "Romanian; Moldavian; Moldovan", "Romanian")) %>% 
  kable(digits = 2, caption = "Number and Percent of Participants by Survey Language in Analysis Data") %>% 
  kable_styling()
```


## Procedure

In the approved protocol, we described a plan for data collection whereby each lab pre-registered a target sample size of 50 after exclusions and stopped collection data on April 1, 2020 or once all contributors reached their pre-registered target sample size. Due to the Covid-19 pandemic, this plan was not feasible. The deadline for data collection was extended to June 1, 2021. Many data collection sites stopped collecting data earlier.

Data collection took place between January 1, 2019 and June 1, 2021. Some participants completed the study survey from a campus laboratory. All participants completed an online survey that included a consent form. After providing informed consent, participants read and answered questions about three vignettes whose content and conditions varied according to the random presentation feature in SocSciSurvey and Qualtrics. The vignettes used in the study were selected on the basis of pretesting in English, described in Appendix X. 

Vignette content varied by subject and identification target. There were three vignette scenarios that were randomly presented to participants: the "Squirrel/Darrel" vignette from Turri et al. (2015), the “Fake Barn/Gerald” vignette from Colaca et al. (2014; altered to include matched knowledge and ignorance control conditions), and the “Diamond/Emma” vignette from Nagel, San Juan, & Mar (2013). The vigenettes are reported in full in Appendix X.
  These vignettes all describe counterfiet object Gettier cases. The primary research aim for this project was to replicate Experiment 1 from Turri et al., (2015), which used a counterfeit object Gettier case ("Squirrel/Darrel"). The two vignettes that were not used in Experiment 1 of Turri et al. (2015) were selected on the basis of their similarity to the original vignette, their quality, and their prevalence in the literature. [Note that on page 33, it says that these vignettes were selected because they had matched controls. But elsewhere, we say that the Gerald vignette didn't have matched controls.]

  Vignettes were pretested for how effectively they manipulated the target construct and how much participants comprehended them (see Appendix X). Some labs tested an additional vignette that was not described in the approved protocol (for more information, see [LINK TO MORE INFORMATION]).

For each vignette, there were three conditions: a Gettier case condition in which subjects correctly identified the target, but not due to their knowledge; a knowledge control condition in which subjects correctly identified the target due to their knowledge; an ignorance control condition in which subjects incorrectly identified the taraget, but not due to their knowledge. Vignette content and condition were randomly assigned. Each participant read and evaluated three vignettes (one of each subject/identification target type and one of each condition).

For each of the three vignettes they read, participants evaluated the subject's knowledge on a series of questions. Student-led teams varied in the exact questions they asked. The percentage of observations that have each question among all vignettes for all participants in the final data is listed in parentheses after each question description. After each vignette, participants were asked:
1) whether the subject believes or knows, measured either on a continuous scale from 0 to 100 (`r round(pct_complete(final_long$know_vas), 2)`% complete) or as a binary choice (`r round(pct_complete(final_long$know_bin), 2)`% complete);
2) the true correct answer, which functioned as a comprehension question and was measured as a binary choice between the two identification options (`r round(pct_complete(final_long$compr), 2)`% complete);
3) the extent to which the subject's belief was unreasonable or reasonable, measured either on a continuous scale from 0 to 100 or (`r round(pct_complete(final_long$reason_vas), 2)`% complete) as a binary choice (`r round(pct_complete(final_long$reason_bin), 2)`% complete); 
4a) whether or the subject identified the target correctly or incorrectly (`r round(pct_complete(final_long$ri_wr), 2)`% complete) and then,
4b) whether this was due to ability/inability versus good luck/ bad luck, measured either on a continuous scale from 0 to 100 (`r round(pct_complete(final_long$luck_vas), 2)`% complete) or as a binary choice (`r round(pct_complete(final_long$luck_bin), 2)`% complete);
4) an alternative knowledge probe in which participants were asked whether the subject knew or only thought they knew what the identification target was (`r round(pct_complete(final_long$know_alt), 2)`% complete). 

In the original protocol, 4a and 4b were described as being one question, but further piloting revealed that the question confused participants.

After reading three vignettes and answering three sets of questions, participants answered questions related to exclusion criteria and demographics. They described the purpose of the study (used for exclusions), their impression of study materials (not used in any analyses), whether they had participated in a similar study (used for exclusions), their language comprehension of the survey language (used for exclusions), and their age, gender, country, birth country, the number of years they had attended school, and their ethnicity. Participants described their perceptions of their compensation ("Will you receive any kind of compensation or reward for taking part in this study?"), before describing the compensation in more detail (e.g., the number of course credits, the amount of money). Participants also completed a 12-question study experience questionnaire that was not used in analyses.

All materials used in this replication, including the details of these vignettes and related pretests, are available at osf.io/n5b3w.

## Analytic Approach

  All raw data collected for this study were aggregated and analyzed as a single dataset. Multilevel models were used to evaluate hypotheses. The unit of anlaysis was the trial and random intercepts for the vignette, participant, and data collection site were be included to account for the nesting of trials within these groups. 
  The approved protocol did not detail criteria that would be used for testing assumptions or approaches to handling convergence issues. We describe the approach taken to test assumptions and to handling convergence issues in the results section where relevant.

[Error on page 34 -- says that the minimum sample size is 40]

  Analyses were conducted on all raw data collected in SocSciSurvey, and data collected in Qualtrics by two labs. In the original protocol, we planned to evaluate the quality of each student-led team's data, including the raw data, anlalysis scrips, codebooks, cleaned data sets, and narrative summaries of results, and data would be included in analyses only if these products passed a quality check. the original protocol did not describe clear criteria that would be used to detect and correct errors. In order to conduct reproducible, transparent anlayses for this report, all available raw data were used, regardless of the completion or quality of subsequent pedagogical activities.
  Aggregating data required making imputations and other adjustments to account for erros, unpredicted data issues, and differences in how student-led teams measured items (see Table X for a summary of methods deviations at the data collection site level). We describe these imputations and other adjustments in the following subsections.
  
*Compensation*

  Participants were asked to report whether and how they were compensated for their participation. Some student-led teams opted to skip this question because all participants were compensated the same way. The documented method of compensation (e.g., as described in the IRB protocol), was imputed for those missing responses to compensation due to survey programming. Among participants who were asked about their compensation, responses were sometimes missing or discrepant with the documented method of compensation. For student-led teams where fewer than 50% of participants in the final dataset agreed on a method of compensation, the documented method of compensated was imputed for all participants (if a single method of compensation was documented).

*Data collection sites*

  In the approved protocol, data collection was described as taking place in labs. Labs were described as uniquely identifying data collection sites. However, at some data collection sites, multiple student-led teams joined this project (e.g., under the mentorship of the same PI, multiple students joined the project as "labs"). Observations were labeled as belonging to both a "lab" (which we describe as a "student-led team") and a data collection site. For analyses, the data collection site was used in place of the "lab" variable described in the approved protocol. 
  
*Education level*

  All participants were asked a question about their education. Participants who completed the survey in SocSciSurvey were asked about the number of years they had been in school (truncated at 18). Participants who completed the survey in Qualtrics were asked about their educational attainment. Years of education was imputed for participants who reported their educational attainment according to the following scheme, which was designed with input from PIs who oversaw data collection in each country. For participants from the United States, less than a high school education was translated as 10 years, a high school diploma was translated as 12 years, some college or a 2-year college degree was translated as 14 years, a 4-year college degree was translated as 16 years, a master's was translated as 18 years, and a doctorate or professional degree was translated as 20 years. For participants from Portugal, the labels were the same except that a 4-year college degree was translated as 15 years, a doctorate or professional degree was translated to 21 years., less than a high school education was translated as 10 years, a high school diploma was translated as 12 years, some college was translated as 16 years, a masters was translated as 18 years, and a graduate degree was translated as 20 years. These translated values were imputed, but with truncation to match how this item was measured in SocSciSurvey. Any value above 17 was imputed as 18.
  Participants were asked to report their gender, and were given three response options. The vast majority of participants selected "male" or "female" (_n_ identified as neither = `r final_demographics %>% filter(gender == "other") %>% nrow()`)

[Need to either collect information about the analyses people did or report that this is a deviation from the original protocol]

## Sample Size Determination

  The approved protocol described power analyses. The text from the original protocol is reproduced in full in Appendix X, and is summarized here. Power anlyses suggested that, given 3 vignettes per participant and 9 labs, at least 32 participants per lab (288 total participants; 864 total observations), would be required to detect an effect of X size at a power of at least .90 with an alpha of .05.
  Considering the high potential for attrition and heterogeneity at the data collection site level, a target sample size of 50 participants per lab was set. 


# Results

  In the approved protocol, the results section focused heavily on the project's logistics and structured results reporting in ways that would not allow for a transparent and thorough description of model fit and other important aspects of results, like assumption checks.
  There were `r length(unique(final_long$Person))` data collection sites in the final dataset. The number of participants at each site varied (see Table X). In the approved protocol, we anticipated that all data collection sites would contribute data from at least 50 participants, after exclusions. `r final_long %>% group_by(Person, id) %>% count() %>% group_by(Person) %>% count() %>% filter(n < 50) %>% nrow()` sites fell short of this threshold.
  The approved protocol described testing assumptions before conducting analyses (for full results of the following assumption checks, see Appendix X). Assumptions of and related to linearity are primarily relevant for the anlayses of the continuously measured dependent variables. The continuous knowledge attribution was dramatically bimodal when examined unconditionally and by vignette and condition.

  A linear model that predicted continuously measured knowledge attribution as a function of condition, with covariates of compensation, age, gender, and education, produced a bimodal residual distribution, indicating a violation of the residual normality assumption. Further, a plot of residuals by fitted values suggests that residuals vary as a function of predicted values, suggesting a violation of the homoscedasticity assumption. Similar patterns of results suggested that the assumptions of linear regression were also not met for continuously measured reasonableness or luck.

  It is generally not recommended to transform continuous varibles in to discreet variables for anlayses (cite). For the present analyses, however, splitting the continuously measured versions of dependent variables such that scores at and below 40 and scores at and above 60 were classified into a discreet category allows us to validly interpret model results and also test whether the method of measurement (continous or binary) affects judgments. So, this was the approach taken.

*Knoweldge attributions*

  To determine whether participants made different attributions about vignette subject's knowledge as a funtion of the vignette's knowledge condition, we estimated a series of logistic regressions. We analyzed responses originally reported on continuous and binary scales together. Listwise deletion was used to handle missing data. 
  First, a baseline intercept-only model was estimated. Then, models with random intercepts for vignette, person, and data collection site were added sequentially. 
  Compared to the baseline model (AIC = `r round(AIC(k.model.1), 2)`), a model with a random intercept for vignette (AIC = `r round(AIC(k.model.2), 2)`) explained more variance. Psuedo Rsqaured values suggest that vignette accounts for `r round(r.squaredGLMM(k.model.2)[2,2]*100, 1)`% to `r round(r.squaredGLMM(k.model.2)[1,2]*100, 1)`% of the random variance in knowledge attributions. People tended to attribute knowledge differently in each vignette. People attributed Darrel's identification to his knowledge and his belief with roughly equal frequency, but slightly favored attributing his knowledge. People tended to attribute Emma's identification to her belief much more often than to her knowledge. People tended to attribute Gerald's identification to his belief slightly more often than to his knowledge. 
  
```{r}
tidy(k.model.2) %>% 
  clean_variable_names() %>% 
  kable(caption = "Explaining Variance in Knowledge Attributions with a Random Intercept for Vignette") %>% 
  kable_styling()
```

  A model with a random intercept for vignette nested within participant (AIC = `r round(AIC(k.model.3), 2)`) explained similar amounts of variance to a model with a random intercept for vignette alone. Psuedo Rsqaured values suggest that this model accounts for `r round(r.squaredGLMM(k.model.3)[2,2]*100, 1)`% to `r round(r.squaredGLMM(k.model.3)[1,2]*100, 1)`% of the random variance in knowledge attributions.
  Next, a model with a random intercept for vignette nested in participant nested in data collection site was estimated (AIC = `r AIC(k.model.4)`). The addition of data collection site was not useful relative to the previous model. Psuedo Rsqaured values suggest that this model accounts for `r round(r.squaredGLMM(k.model.4)[2,2]*100, 1)`% to `r round(r.squaredGLMM(k.model.4)[1,2]*100, 1)`% of the random variance in knowledge attributions.
  Next, covariates were added to the model as fixed effects to account for the effects of participant age, perceived compensation (a binary variable, with 0 = no perceived compensation and 1 = perceived compensation), gender (a binary variable, with 0 = female and 1 = male), and education (in years) on their knowledge attributions (AIC = `r round(AIC(k.model.5), 2)`). Relative to the model without covariates, this model was more useful in explaining variance in knowledge attribution. However, no covariates predicted knowledge attributions accounting for all others.
  
```{r}
tidy(k.model.5) %>% 
  clean_variable_names() %>% 
  kable(caption = "Explaining Variance in Knowledge Attributions with Random Intercepts for Vignette/Participant/Site and Covariates") %>% 
  kable_styling()
```

  Finally, a model was estimated that included knowledge condition as a fixed effect (AIC = `r round(AIC(k.model.6), 2)`). This model performed better than the previous model, suggesting that there was an effect of vignette condition on people's knowledge attributions. Both the knowledge condition and the ignorance condition differed from the Gettier condition (see Table X). In the knowledge condition, people were much more likely to attribute subject's identification to their knowledge rather than their belief. In the Gettier condition, people were slighltly more likely to attribute belief than knowledge and in the ignorance condition, people were much more likely to attribute belief than knowledge. Psuedo Rsqaured values suggest that condition accounts for `r round(r.squaredGLMM(k.model.6)[2,1]*100, 1)`% to `r round(r.squaredGLMM(k.model.6)[1,1]*100, 1)`% of the fixed effect variance in knowledge attributions.

```{r}
tidy(k.model.6) %>% 
  clean_variable_names() %>% 
  kable(caption = "Effect of Condition on Knowledge Attributions") %>% 
  kable_styling()
```


```{r}
table(k.model.6@frame$cond, 
      str_replace(
        str_replace(k.model.6@frame$know_vas_combined, "0", "Knows"),
        "1", "Believes")) 
```

*Does the effect of knowledge condition differ by vignette?*

  To better understand whether the effect of condition varied as a function of the vignette's content, a model was estimated that included an interaction between vignette and subject (AIC = `r round(AIC(k.model.6A), 2)`). This model explained more variance than the model without th einteraction between condition and vignette. As shown in Figure X, although the general pattern is the same for all vignettes, when making attirbutions about the Emma vignette, people were more likely to attribute belief in every condition than they were for the other vignettes. Psuedo Rsqaured values suggest that the interaction between condition and vignette accounts for `r round(r.squaredGLMM(k.model.6A)[2,1]*100, 1)`% to `r round(r.squaredGLMM(k.model.6A)[1,1]*100, 1)`% of the random variance in knowledge attributions.
  


```{r}
tidy(k.model.6A) %>% 
  clean_variable_names() %>% 
  kable(caption = "Interaction of Condition and Vignette on Knoweldge Attributions") %>% 
  kable_styling()
```

```{r}
#graph the three way binary 
ggplot(data_graph) +
  geom_mosaic(aes(x = product(know_vas_combined, cond, vignette), 
                  fill = know_vas_combined)) + 
  scale_fill_manual(name = "Knowledge Attribution",
                    values = c("gray", "black")) + 
  scale_x_productlist(breaks = c(0.13,.5,.87),
    labels = c("Darrel", "Emma", "Gerald")) + 
  theme_classic() + 
  xlab("Vignette") + 
  ylab("Condition") +
  ggtitle("Figure X. Rates of Knowledge Attribution by Condition and Vignette")
```

```{r Darrel knowledge effect}
k.dcond_effect <- chisq.test(data_graph$know_vas_combined[data_graph$vignette == "Darrel"], 
           data_graph$cond[data_graph$vignette == "Darrel"]) %>% 
  tidy()

k.dcond_GI <- prop.test(t(k.d_table[1:2, 1:2])) %>% 
  tidy()

k.dcond_GI_v <- v.chi.sq(x2 = prop.test(t(k.d_table[1:2, 1:2]))$statistic, 
         n = sum(t(k.d_table[1:2, 1:2])),
         r = 2, c = 2) 

k.dcond_GK <- prop.test(t(k.d_table[1:2, c(1,3)])) %>% 
  tidy()

k.dcond_GK_v <- v.chi.sq(x2 = prop.test(t(k.d_table[1:2, c(1,3)]))$statistic, 
         n = sum(t(k.d_table[1:2, c(1,3)])),
         r = 2, c = 2) 

```

In the Darrel vignette, people made different attributions in the different conditions X^2(`r k.dcond_effect$parameter[[1]]`) = `r round(k.dcond_effect$statistic[[1]], 2)`, p `r if(round(k.dcond_effect$p.value[[1]], 4) == 0)paste("<.0001")`. The likelihood that people attributed Darrel's identification to his knowledge differed in the ignorance and Gettier conditions such that people were more likely to attribute knowledge in the Gettier condition (`r round(k.dcond_GI$estimate1, 2)`) than in the ignorance condition (`r round(k.dcond_GI$estimate2, 2)`; Cramer's `r k.dcond_GI_v$estimate`, `r k.dcond_GI_v$statistic`). The likelihood that people attributed Darrel's identification to his knowledge also differed in the knowledge and Gettier conditions such that people were more likely to attribute knowledge in the knowledge condition (`r round(k.dcond_GK$estimate2, 2)`than in the Gettier condition (`r round(k.dcond_GK$estimate1, 2)`; Cramer's `r k.dcond_GK_v$estimate`, `r k.dcond_GK_v$statistic`). 

```{r Emma knowledge effect}
k.econd_effect <- chisq.test(data_graph$know_vas_combined[data_graph$vignette == "Emma"], 
           data_graph$cond[data_graph$vignette == "Emma"]) %>% 
  tidy()

k.econd_GI <- prop.test(t(k.e_table[1:2, 1:2])) %>% 
  tidy()

k.econd_GI_v <- v.chi.sq(x2 = prop.test(t(k.e_table[1:2, 1:2]))$statistic, 
         n = sum(t(k.e_table[1:2, 1:2])),
         r = 2, c = 2) 

k.econd_GK <- prop.test(t(k.e_table[1:2, c(1,3)])) %>% 
  tidy()

k.econd_GK_v <- v.chi.sq(x2 = prop.test(t(k.e_table[1:2, c(1,3)]))$statistic, 
         n = sum(t(k.e_table[1:2, c(1,3)])),
         r = 2, c = 2) 

```

In the Emma vignette, the pattern was similar. People made different attributions in the different conditions X^2(`r k.econd_effect$parameter[[1]]`) = `r round(k.econd_effect$statistic[[1]], 2)`, p `r if(round(k.econd_effect$p.value[[1]], 4) == 0)paste("<.0001")`. The likelihood that people attributed Emma's identification to her knowledge differed in the ignorance and Gettier conditions such that people were more likely to attribute knowledge in the Gettier condition (`r round(k.econd_GI$estimate1, 2)`) than in the ignorance condition (`r round(k.econd_GI$estimate2, 2)`; Cramer's `r k.econd_GI_v$estimate`, `r k.econd_GI_v$statistic`). The likelihood of knowledge attribution also differed in the knowledge and Gettier conditions such that people were more likely to attribute knowledge in the knowledge condition (`r round(k.econd_GK$estimate2, 2)`) than in the Gettier condition (`r round(k.econd_GK$estimate1, 2)`; Cramer's`r k.econd_GK_v$estimate`, `r k.econd_GK_v$statistic`). 

```{r Gerald knowledge effect}
k.gcond_effect <- chisq.test(data_graph$know_vas_combined[data_graph$vignette == "Gerald"], 
           data_graph$cond[data_graph$vignette == "Gerald"]) %>% 
  tidy()

k.gcond_GI <- prop.test(t(k.e_table[1:2, 1:2])) %>% 
  tidy()

k.gcond_GI_v <- v.chi.sq(x2 = prop.test(t(k.g_table[1:2, 1:2]))$statistic, 
         n = sum(t(k.e_table[1:2, 1:2])),
         r = 2, c = 2) 

k.gcond_GK <- prop.test(t(k.e_table[1:2, c(1,3)])) %>% 
  tidy()

k.gcond_GK_v <- v.chi.sq(x2 = prop.test(t(k.g_table[1:2, c(1,3)]))$statistic, 
         n = sum(t(k.e_table[1:2, c(1,3)])),
         r = 2, c = 2) 

```


In the Gerald vignette,the overall pattern was the same. People made different attributions in the different conditions X^2(`r k.gcond_effect$parameter[[1]]`) = `r round(k.gcond_effect$statistic[[1]], 2)`, p `r if(round(k.gcond_effect$p.value[[1]], 4) == 0)paste("<.0001")`. As with Darrel and Emma, the likelihood that people attributed Gerald's identification to his knowledge differed such that people were more likely to attribute knowledge in the Gettier condition (`r round(k.gcond_GI$estimate1, 2)`) than in the ignorance condition (`r round(k.gcond_GI$estimate2, 2)`; Cramer's `r k.gcond_GI_v$estimate`, `r k.gcond_GI_v$statistic`). In addition, people were more likely to attribute knowledge to Gerald in the knowledge condition (`r round(k.gcond_GK$estimate2, 2)`) than in the Gettier condition (`r round(k.gcond_GK$estimate1, 2)`; Cramer's `r k.gcond_GK_v$estimate`, `r k.gcond_GK_v$statistic`). 

Although the pattern of results was the same for all three vignettes, Cramer's V shows that the likelihood differences varied by vignette. For example, the likelihood difference between the Gettier condition and ignorance condition was much smaller in the Emma vignette than in the Darrel and Gerald vignettes. The likelihood difference between the Gettier and knowledge conditions was much smaller in the Darrel vignette than in the Emma and Gerald vignettes.

*Does the effect of knowledge condition differ in participants recruited through Mturk?*

Most data in the analysis sample came from participants recruited through university or community subjects pools or social media posts by university researchers. Some data came from participants recruited through Amazon Mturk. To test whether the effects of condition differed as a function of how participants were recruited, we estimated a model that included an interaction between condition and a variable that indicated whether or not an observation came from an Mturk participant (recruitment type; AIC = `r round(AIC(k.model.6B), 2)`). This model performed better than a model without the condition by recruitment type interaction. However, the interaction between condition and recruitment type was not significant, and there was no evidence that the effect of condition differed as a function of how participants were recruited.

```{r}
tidy(k.model.6B) %>% 
  clean_variable_names() %>% 
  kable(caption = "Interaction of Condition and Participant Recruitment Type") %>% 
  kable_styling()
```


*Does the effect of knowledge condition differ as a function of how attributions were measured?*

In the approved protocol, we planned to replicate analyses using different types of attribution measurement: continuously measured attributions on a scale from 0 to 100 and attributions measured as a choice between two binary options. Continously measured attirbutions were strongly bimodally distributed, and did not support linear modeling. Data were therefore combined. However to test whether the effect of condition on knowledge attributions differed as a function of measurement type, we estimated a model that included an interaction between condition and measurement type (continuous or binary; AIC = `r round(AIC(k.model.6C), 2)`). This model did not perform better than a model without the condition by measurement type and there was no evidence that the effect of condition differed depending on how knowledge attributions were measured.


# Disclosures


*Data, materials, and online resources:* Deidentified raw data and deidentified data with exclusions are are posted publicly on our master OSF page (https://osf.io/n5b3w/), and each contributing site has posted their data on an OSF page linked to our master OSF page.


*Reporting:*

 “We report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study” (see Simmons, Nelson, & Simonsohn, 2011).
 
*Ethical approval:*

All contributing labs were required to submit their local institutional ethics approval prior to data collection as part of their pre-registstration and CREP review process and will be carried out in accordance with the provisions of the World Medical Association Declaration of Helsinki. All participating labs posted their ethics approval to their lab's OSF page for this study. 

*Author Contributions:*

TBD

*Conflicts of Interest:*

The author(s) declare that there were no conflicts of interest with respect to the authorship or the publication of this article.

*Funding:*

TBD

*Supplemental Material:*

If Supplemental Material will be posted on the journal’s Web site, include this heading and the appropriate link will be added during editing.

*Prior versions:*

If part or all of a submitted manuscript was previously posted to a blog or to a preprint archive, the authors should provide a link to that source and briefly indicate what aspects of the submitted manuscript are shared with that prior version.

# Appendix

### Vignettes

*For the Gerald vignette, all participants read:*

“Gerald is driving through the countryside with his young son Andrew. Along the way he sees numerous objects and points them out to his son. 'That's a cow, Andrew,' Gerald says, 'and that over there is a house where farmers live.' Gerald has no doubt about what the objects are.

What Gerald and Andrew do not realize is the area they are driving through was recently hit by a very serious tornado. This tornado did not harm any of the animals, but did destroy most buildings. In an effort to maintain the rural area's tourist industry, local townspeople built new houses in the place of the destroyed houses. These new houses were rebuilt with all the materials necessary for them to look exactly like the original houses from the road, and they are also fully furnished and can now be used as actual housing.”

In the knowledge condition, participants read:

“Having just entered the tornado-ravaged area, Gerald notices the many houses lining the roads. When he tells Andrew 'That's a house,' the object he sees and points at is a real house that has survived the tornado and not one of the new houses.”

In the ignorance condition, participants read:

“Having driven through the tornado-ravaged area, Gerald has encountered many of these fake houses. When he tells Andrew 'That's a house,' the object he sees and points at is a fake house that was built after the tornado and is not actually a house.”

In the gettier condition, participants read:

“Having just entered the tornado-ravaged area, Gerald has not yet encountered any fake houses. When he tells Andrew 'That's a house,' the object he sees and points at is a real house that has survived the tornado and not one of the fake houses.”

*For the Emma vignette, all participants read:*

“Emma is shopping for jewelry. She goes into a nice-looking store and selects a necklace from a tray marked "Diamond Earrings and Pendants." "What a lovely diamond!" she says as she tries it on. Emma could not tell the difference between a real diamond and a cubic zirconium fake just by looking or touching.”

In the knowledge condition, participants read:

“However, this particular store has very honest employees who have a really positive reputation for their guaranteed real diamonds; in the tray Emma chose, all of the pendants had real diamonds rather than fake cubic zirconium stones (and the one she chose was really nice).”

In the ignorance condition, participants read:

“Unfortunately, this particular store has very dishonest employees who have been stealing real diamonds and replacing them with fakes; in the tray Emma chose, almost all of the pendants had cubic zirconium stones rather than diamonds (and the one she chose was in fact fake).”

In the gettier condition, participants read:

“Unfortunately, this particular store has very dishonest employees who have been stealing real diamonds and replacing them with fakes; in the tray Emma chose, almost all of the pendants had cubic zirconium stones rather than diamonds (but the one she chose happened to be real).”

*For the Darrel vignette, all participants read:*

“Darrel is an ecologist collecting data on red speckled ground squirrels in Canyon Falls national park. The park is divided into ten zones and today Darrel is working Zone 3. While scanning the river valley with his binoculars, Darrel sees a small, bushy-tailed creature with distinctive red markings on its chest and belly. The red speckled ground squirrel is the only native species with such markings. Darrel records in his journal, ‘At least one red speckled ground squirrel in Zone 3 today.’


In the knowledge condition, participants read:

“Ecologists are unaware that a complex network of aquifers recently began drying up in the park. These aquifers carry vital nutrients to the trees and other forms of plant life that support the squirrels. And the aquifers in the river valley running through Zone 3 are no exception. The animal Darrel is looking at is indeed a thirsty red speckled ground squirrel.”

In the ignorance condition, participants read:

“Ecologists are unaware that a non-native species of prairie dog recently began invading the park. These prairie dogs also have red markings on their chest and belly. When these prairie dogs tried to invade Zone 3, the red speckled ground squirrels were unable to completely drive them away. And, the animal Darrel is looking at is indeed one of the prairie dogs.”

In the gettier condition, participants read:

“Ecologists are unaware that a non-native species of prairie dog recently began invading the park. These prairie dogs also have red markings on their chest and belly. When these prairie dogs tried to invade Zone 3, the red speckled ground squirrels were unable to completely drive them away. Still, the animal Darrel is looking at is a red speckled ground squirrel.”



### Exclusion ratings

**How exclusions were made**

No or NA gets 0 points 
Maybe gets 1 point
Yes/test gets 2 points
Participants are marked as "excluded" if they get 4 total points across three coders 

Participants are also marked as "nonsense" if they did not write a legible answer or simply typed gibberish. These data points are not excluded but marked.

**Instructions Given to Raters**

Note: These instructions were adapted from instructions written by William McAuliffe and Hannah Moshontz for an unrelated project

We need help coding open-ended responses that will inform our pre-registered exclusion criteria for this project. Specifically, we will exclude data on the basis of a suspicion check (whether people guess the study hypothesis) and previous study participation (whether people describe having participated in similar studies before). 

All participants were asked two questions (with some labs asking slight variations):
What is, in your opinion, the purpose of this study? (purpose)
Have you ever participated in a similar study? If yes, please describe the study. (previous)

Your task is to evaluate people’s answers to these questions. We will have 2 people evaluate every response and then we will exclude people based on the average.

For each question this is how we would like you to evaluate answers. If you are coding from a language other than English, please directly assess the question (rather than translating it) and provide a code/label in English (yes, maybe, no, test, as described below).

**purpose**

_yes_

The participant identified that we are studying justified true belief and gettier cases.

Example “yes” coding cases: “To test exceptions to the Justified True Belief theory”

_maybe_

The participant describes something similar to the true study hypothesis (true knowledge is different from a lucky or incidentally correct belief). 

Example “maybe” coding cases: “To see if a story can change ones perception of knowledge based on luck or ability”

_no_

The participant did not identify the study hypothesis or offer a very vague description, which might include the words belief or knowledge. 

Example “no” coding cases: “I think the purpose was to see how do people classify if someone knows something or if they just strongly agree with it”; OR “understand how people view scenarios based on the words used to describe them"

_test_ 

The response indicates that it is a test case    

Example “test” coding case: “TEST”; OR “test”; OR “this is a test”

_NA_ 

If you are unsure how to code a response, you can write NA.

Example “NA” coding case: “nnnnnnnnnnn”

**Previous**

_yes_ 

The participant has participated in this exact study before, or an exact replication of it.

Example “yes” coding cases: “Yes, I completed this study before.” 

_maybe_ 

The participant has participated in a similar study before, or may have based on their description.

Example “maybe” coding cases:  “Yes another study that was very similar.”; “Yes, I have participated in a study that asked similar questions but had slightly different scenarios”

_no_ 

The participant has not participated in this study or a similar study before based on their description.

Example “no” coding cases: “nope”; “Yes, I have participated in a study for course credit before.”’; “Yes, I have done studies where I read scenarios and answered questions about them.”

_test_ 

The response indicates that it is a test case        

Example “test” coding case: “TEST”; OR “test”; OR “this is a test”

_NA_ 

If you are unsure how to code a response, you can write NA.

Example “NA” coding case: “nnnnnnnnnnn”

**Do’s and Don’ts**
Take breaks! This work is hopefully interesting, but it can be cognitively exhausting. If you are having trouble paying attention while you are doing this or if you feel tired of it, please take a break. 

After you label a response, do not go back and change it later. This may be tempting to do after mentally comparing how you rated different responses, but just carefully work through each response and know that your initial rating is final.

Don’t discuss your ratings with other raters—this will invalidate everyone’s work.
Do assign labels for every response in your assigned sheet(s). If you would like to contribute more, please email the person listed at the top of this sheet.

**To summarize, for each set of answers**
Read the answer to the question and assign a label that describes either whether people intuited the study hypothesis (for purpose) or whether people participated in a similar study previously (for previous)

**Coding form includes**
[id] A subject id number
[survey_lang]
[purpose/previous] The answer people gave to the question
[code] The code/label that you are assigning to the answer (yes, no, maybe, test)



### Demographics

*Version A*
Used by the following data collection sites in SSS: [List sites that used this option here]

White / European descent
Black / African descent
Latino*a / Latin American descent
Australian descent
Asian
Southeast Asian descent
Native American
Hawaiian descent / Pacific Islands
Other

*Version B*
Used by the following data collection sites in SSS: [List sites that used this option here]

European descent
African descent
Latino*a / Latin American descent
Indigenous Australian or Torres Strait Islander descent
East Asian descent
South Asian descent
Pacific Island descent
Native American descent

*Version C*
Used by the following data collectoin sites in Qualtrics: [List sites that used this option here]
White/European
Black/African American
Hispanic Latino
East or Southeast Asian / Pacific Islander (e.g. from Japan, China, Korea, Vietnam, Thailand, Philippines, native Hawaiian)
South Asian (e.g. from India, Pakistan)
I prefer not to answer this question
Other

