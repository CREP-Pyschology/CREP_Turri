---
title: "PSA004 Method and Results"
author: "Hannah"
date: "1/18/2022"
output: word_document
---


# Run the analysis script

```{r, child = '../05_Analysis/ACrep_Analysis_V2.Rmd', include = FALSE, results = FALSE}
```

# Set up 

```{r packages}
library(janitor)
library(stringr)
library(kableExtra)
library(countrycode)
library(ISOcodes)
#library(tidylog)
library(naniar) # to evaluate missing data
library(broom.mixed) # for nicely presented results
```

```{r functions}

#a function to make names in the tidy model objects less confusing
#used to prep results tables
clean_variable_names <- function(tidy_model_obj){
  
  tidy_model_obj %>% 
    mutate(group = str_replace(group, "person_code.*", "site"),
           group = str_replace(group, "id:vignette","participant")) %>% 
    mutate(term = str_replace(term, "compYes", "compensation"),
           term = str_replace(term, "gender2male", "gender"))
  
}

```

Method
This project was designed to align  undergraduate research training and learning with contributions to science. It was conceived of and led by the Collaborative Replications and Education Project (CREP; Wagge et al., 2019) in collaboration with the Psychological Science Accelerator (PSA; Moshontz et al., 2019). For the students who served the role of researcher in this study, the project involved collecting data and completing a series of tasks with pedagogical value, like independently designing an analysis plan, completing a pre-registration, independently executing analyses, and posting the study materials, data, and results summaries in a central repository (Open Science Framework; LINK). Each student-led team submitted a protocol for review to a CREP reviewer. Teams could not contribute to data collection until the protocol was approved. For more information about this process and detailed descriptions of logistical considerations, see Appendix X. 
In total, 69 student-led teams signed up to collect data for this project. At some sites, multiple teams completed the project. Because observations collected by different teams were  sometimes organized within a single data collection site, counts of student-led teams sometimes differ from counts of data collection sites. Further, some teams that were approved to collect data did not contribute data to this project, either because they did not collect any data (e.g., due to campus closures during the Covid-19 pandemic) or because data were collected in a way that rendered them unusable for analyses (e.g., vignettes were not appropriately randomized). Of the teams that originally signed up, 32 either did not submit protocols for review or submitted protocols but did not complete revisions required to begin data collection. In total, 22 teams completed the entire project, including the purely pedagogical tasks, and the data from XX teams were included in analyses. Data collection sites sometimes had multiple teams and spanned 20 countries including many world regions. See Table X for a summary of student-led teams, and Table X for a summary of data collection sites.


# EDA on the analysis set

A few notes about variables:
- person_code_code is a unique lab identifier (identifies PI)
- lab_id is a not a unique lab identifier, but rather identifies the undergraduate PI
(and some of these undergraduate PIs were students with the same lab PI)
- lab_country is the variable we are using to identify country/region
- un_region groups lab country into larger regions
- source identifies the method of data collection
- id uniquely identifies each participant by concatenating the source (qualtrics vs socscisurvey),
undergraduate PI (lab_id), and the unique identifier (case, which was of a different format depending on source)
- variables ending in valid are logical and identify valid cases (in the "final_long" dataset, there will not be variance)
- variables ending in order indicate the order in which vignettes or condition were presented (varies by participant),
or the order in which binary DVs were presented (for socscisurvey, this varies by person_code within lab such that people 
were presented with "normal" (*not sure what direction this is*) or "swapped", but for Qualtrics, this was randomized 
within person_code and so is coded as "mixed" and and we do not have more detailed information about order in the final dataset. also one lab didn't properly randomize.)
- 2104 N are missing age. are these likely test observations? and so this exclusion and over 100 were a way to try to catch the test observations.


Results
 To better test our research questions, we implemented analyses that differ from those we originally planned. All deviations from the approved protocol are summarized in Table X. The results as they appeared in the approved protocol are included in full, with updated statistics where possible, in Appendix X.
Knowledge Attributions
The goal of the present work was to provide a well-powered estimate of the magnitude and prevalence of Gettier intuitions (i.e., the difference in knowledge attribution between Gettier and knowledge conditions) across different scenarios and testing sites. [Restate primary aim/hypothesis]. To determine whether participants attributed knowledge to the protagonist at different rates as a function of condition, we estimated a series of multilevel logistic regression models. We analyzed responses originally reported on continuous and binary scales together using a combined binary variable with 0 indicating knowledge and 1 indicating belief rather than knowledge. Listwise deletion was used to handle missing data. After estimating a baseline intercept-only model, we fit models with random intercepts for vignette, person, and data collection site added sequentially. Compared to the baseline model (AIC = 11509.11), a model with a random intercept for vignette (AIC = 10856.51) explained more variance. Pseudo-R2 values suggested that vignette accounts for 8.1% to 10.2% of the random variance in knowledge attributions. Inspection of frequencies indicated that participants attributed knowledge most frequently in response to the Gerald vignette (XX%) and least frequently in response to the Emma vignette (XX%).
 
effect
group
term
estimate
std.error
statistic
p.value
fixed
NA
(Intercept)
0.5145899
0.3533251
1.45642
0.1452764
ran_pars
vignette
sd__(Intercept)
0.6106306
NA
NA
NA

 
 


Darrel
Emma
Gerald
Knows
1465
581
1244
Believes
1379
2265
1594

 
A model with a random intercept for vignette nested within participant (AIC = 10858.51) explained similar amounts of variance (8.1% to 10.2% according to Pseudo-R2) as a model with a random intercept for vignette alone. Next, we estimated a model with a random intercept for vignette nested in participant nested in data collection site (AIC = 10860.51). The addition of data collection site likewise did not improve model fit (Pseudo-R2 = .081 - .102). Next, participant age, compensation, gender, and education (in years) were added to the model predicting knowledge attributions as fixed effects (AIC = 10741.54). Relative to the model without covariates, this model was more useful in explaining variance in knowledge attribution. However, no covariates predicted knowledge attributions accounting for all others (see Table X).
effect
group
term
estimate
std.error
statistic
p.value
fixed
NA
(Intercept)
0.4657943
0.3778763
1.2326634
0.2177014
fixed
NA
compensation
-0.0495927
0.0551008
-0.9000363
0.3681010
fixed
NA
age
-0.0036258
0.0023656
-1.5327494
0.1253376
fixed
NA
gender
0.0752331
0.0506316
1.4858932
0.1373074
fixed
NA
education
0.0111057
0.0088550
1.2541718
0.2097796
ran_pars
site
sd__(Intercept)
0.0000497
NA
NA
NA
ran_pars
participant
sd__(Intercept)
0.0000000
NA
NA
NA
ran_pars
vignette
sd__(Intercept)
0.6092371
NA
NA
NA

 
Finally, we estimated a model that included knowledge condition as a fixed effect (AIC = 9689.84). This model served as the key replication test of Turri et al. (2015). This model performed better than the previous model and revealed an effect of condition on knowledge attribution. Participants were more likely to attribute knowledge to the protagonist in the knowledge condition vignette than to the protagonists in the ignorance and Gettier condition vignettes; further, the ignorance condition differed from the Gettier condition (see Table X). Pseudo-R2 values suggest that condition accounted for 12.6% to 15.2% of the fixed effect variance in knowledge attribution. Thus, we did not fully replicate the results of Turri et al. (2015, Experiment 1), who found no difference in knowledge attribution between the knowledge and Gettier conditions. 
 
Table X. Effect of Condition on Knowledge 
effect
group
term
estimate
std.error
statistic
p.value
fixed
NA
(Intercept)
0.2789995
0.4234774
0.6588297
0.5100051
fixed
NA
compensation
-0.0561355
0.0588762
-0.9534497
0.3403623
fixed
NA
age
-0.0037802
0.0025356
-1.4908646
0.1359970
fixed
NA
gender
0.0974744
0.0541557
1.7998905
0.0718779
fixed
NA
education
0.0117522
0.0094777
1.2399864
0.2149804
fixed
NA
condIgnorance
1.3677427
0.0646612
21.1524533
0.0000000
fixed
NA
condKnowledge
-0.5834665
0.0568235
-10.2680553
0.0000000
ran_pars
site
sd__(Intercept)
0.0000000
NA
NA
NA
ran_pars
participant
sd__(Intercept)
0.0000000
NA
NA
NA
ran_pars
vignette
sd__(Intercept)
0.6852758
NA
NA
NA

 
Does the effect of condition differ by vignette?
To better understand whether the effect of condition varied as a function of the vignette’s content, a model was estimated that included an interaction between vignette and condition (AIC = 9645.97). This model explained more variance than the model without the interaction. As shown in Figure X, the general pattern of results was the same for every vignette; however,  Pseudo-R2 values suggest that the interaction between condition and vignette accounts for 20.1% to 24.5% of the random variance in knowledge attributions. In other words, the differences in the conditions varied according to which vignette they were matched. 
effect
group
term
estimate
std.error
statistic
p.value
fixed
NA
(Intercept)
-0.5287117
0.1602953
-3.2983597
0.0009725
fixed
NA
compensation
-0.0557991
0.0591595
-0.9431984
0.3455794
fixed
NA
age
-0.0037938
0.0025435
-1.4915756
0.1358104
fixed
NA
gender
0.1044569
0.0544196
1.9194704
0.0549248
fixed
NA
education
0.0106236
0.0095259
1.1152428
0.2647464
fixed
NA
condIgnorance
1.7147785
0.1025940
16.7142188
0.0000000
fixed
NA
condKnowledge
-0.3537180
0.0972970
-3.6354464
0.0002775
fixed
NA
vignetteEmma
2.0438581
0.1091218
18.7300700
0.0000000
fixed
NA
vignetteGerald
0.5188058
0.0933380
5.5583581
0.0000000
fixed
NA
condIgnorance:vignetteEmma
-1.0309541
0.1732313
-5.9513153
0.0000000
fixed
NA
condKnowledge:vignetteEmma
-0.5507109
0.1468808
-3.7493735
0.0001773
fixed
NA
condIgnorance:vignetteGerald
-0.3500298
0.1458517
-2.3999012
0.0163995
fixed
NA
condKnowledge:vignetteGerald
-0.2332559
0.1355456
-1.7208661
0.0852751
ran_pars
site
sd__(Intercept)
0.0000099
NA
NA
NA
ran_pars
participant
sd__(Intercept)
0.0000115
NA
NA
NA
ran_pars
vignette
sd__(Intercept)
0.0000000
NA
NA
NA

 

In responding to the Darrel vignette, participants attributed knowledge at different rates according to the vignette’s conditions, χ2(2) = 482.47, p < .001. Participants were more likely to attribute knowledge when responding to the Gettier condition version (0.62) than to the ignorance condition version (0.23; Cramer’s V = .40, 95% CI [.35, .44], χ2(1) = 296.80, p < .001). They were also more likely to attribute knowledge to Darrel when responding to the knowledge condition version (0.7) than to the Gettier condition version (0.62; Cramer’s V = .08, 95% CI [.04, .13], χ2(1) = 12.81, p < .001). 
The pattern of responding was similar for the Emma vignette; the likelihood that participants attributed knowledge to Emma differed according to the vignette’s condition, χ2(2) = 186.16, p < .001. Participants were more likely to attribute knowledge when responding to the Gettier condition of the Emma vignette (0.17) than to the ignorance condition of the Emma vignette (0.1; Cramer’s V = .11, 95% CI [.07, .16], χ2(1) = 24.13, p < .001). The likelihood of knowledge attribution was higher for the knowledge version of the vignette (0.34) than for the Gettier version (0.17; Cramer’sV = .19, 95% CI [.15, .24], χ2(1) = 68.77, p < .001). 
In response to the Gerald vignette, participant knowledge attributions similarly differed according to vignette condition, χ2(2) = 382.75, p <.0001. Participants were more likely to attribute knowledge in response to the Gettier condition vignette (0.17) than to the ignorance condition vignette (0.1; Cramer’s V = .31, 95% CI [.27, .35], χ2(1) = 180.97, p < .001). In addition, they were more likely to attribute knowledge to Gerald in the knowledge condition (0.34) than in the Gettier condition (0.17; Cramer’s V = .14, 95% CI [.10, .19], χ2(1) = 38.52, p < .001).
To interpret the condition by vignette interaction, we examined Cramer’s V for the analyses of each vignette. This approach revealed that the likelihood of knowledge attributions in the Gettier and ignorance conditions differed less for the Emma vignette than for the Darrel and Gerald vignettes. Additionally, the Gettier and knowledge conditions of the Darrel vignette produced a smaller difference in likelihood than that for those conditions of the other two vignettes. Thus, participants demonstrated Gettier intuitions in all three vignettes (i.e., participants were more likely to deny knowledge in Gettier cases than in JTB cases), but these Gettier intuitions were weaker for the Darrel vignette and stronger for the Emma vignette.  [Restate in terms of Gettier intuitions].
 
Reasonableness 
As a secondary dependent measurement, judgments of reasonableness were predicted in a series of logistic regression models paralleling those for knowledge attributions. Responses originally reported on continuous and binary scales were combined to create a single binary measure (see Analytic Approach) with 0 indicating reasonable and 1 indicating unreasonable. Listwise deletion was used to handle missing data for each model. Compared to a baseline intercept-only model (AIC = 4305.05), a model with a random intercepts for vignette (AIC = 4288.37) explained more variance. The likelihood of the protagonist being judged as reasonable varied by vignette; although, overall participants were far more likely to respond that the protagonist was reasonable than unreasonable in all three vignettes. Pseudo-R2 values suggest that vignette accounted for a small portion of the random variance in reasonableness attributions (between 0.3% to 1.4%). Collapsing across conditions, participants were more likely to judge Emma as unreasonable than Gerald. Participants were more likely to judge Gerald as unreasonable than Darrel. 
 


Darrel
Emma
Gerald
Reasonable
2713
2608
2686
Unreasonable
148
248
187

 
effect
group
term
estimate
std.error
statistic
p.value
fixed
NA
(Intercept)
-2.641380
0.1318169
-20.03825
0
ran_pars
vignette
sd__(Intercept)
0.215616
NA
NA
NA

 
A model with a random intercept for vignette nested within participant (AIC = 4290.37) explained similar amounts of variance (Pseudo-R2 = .003 - .014) as a model with a random intercept for vignette alone. Next, we estimated a model with a random intercept for vignette nested in participant nested in data collection site (AIC = 4292.366579). The addition of data collection site did not increase explained variance; Pseudo-R2 values suggest that this model accounted for 0.3% to 1.4% of the random variance in knowledge attributions.
Next, covariates were added to the model as fixed effects (AIC = 4231.64). Relative to the model without covariates, this model was more useful in explaining variance in judgements of reasonableness. Compensation was associated with reasonableness; participants who were compensated were more likely to judge the protagonist as reasonable (19% increase). Education was also associated with reasonableness. As the participant’s years of education decreased, the likelihood that they would judge the protagonist as reasonable increased.
effect
group
term
estimate
std.error
statistic
p.value
fixed
NA
(Intercept)
-1.6399477
0.2615472
-6.2701782
0.0000000
fixed
NA
compensation
-0.1894869
0.0976929
-1.9396191
0.0524260
fixed
NA
age
0.0020411
0.0043256
0.4718661
0.6370223
fixed
NA
gender
0.1228101
0.0922162
1.3317617
0.1829385
fixed
NA
education
-0.0685983
0.0145417
-4.7173603
0.0000024
ran_pars
site
sd__(Intercept)
0.0000032
NA
NA
NA
ran_pars
participant
sd__(Intercept)
0.0000498
NA
NA
NA
ran_pars
vignette
sd__(Intercept)
0.2167821
NA
NA
NA

 
Finally, we estimated a model including knowledge condition as a fixed effect (AIC = 4184.76). This model performed better than the previous model and revealed an effect of condition on reasonableness judgment. Participants were more likely to judge the protagonist in the knowledge condition vignette as reasonable than the protagonists in the other two conditions. (see Table X). Protagonists in the ignorance condition vignette were less likely to be judged as reasonable than protagonists in the knowledge and Gettier condition vignettes. Pseudo-R2 values suggest that condition accounted for 0.9% to 4% of the fixed effect variance in knowledge attributions.
effect
group
term
estimate
std.error
statistic
p.value
fixed
NA
(Intercept)
-1.6990105
0.2705165
-6.2806165
0.0000000
fixed
NA
compensation
-0.1918022
0.0981206
-1.9547602
0.0506114
fixed
NA
age
0.0019818
0.0043425
0.4563721
0.6481224
fixed
NA
gender
0.1222403
0.0926033
1.3200423
0.1868209
fixed
NA
education
-0.0688592
0.0146306
-4.7065149
0.0000025
fixed
NA
condIgnorance
0.4159637
0.1004242
4.1420641
0.0000344
fixed
NA
condKnowledge
-0.3369791
0.1173994
-2.8703643
0.0041000
ran_pars
site
sd__(Intercept)
0.1007532
NA
NA
NA
ran_pars
participant
sd__(Intercept)
0.0918509
NA
NA
NA
ran_pars
vignette
sd__(Intercept)
0.2173386
NA
NA
NA

 


Gettier
Ignorance
Knowledge
Reasonable
926
852
935
Unreasonable
31
87
30

 
Does the effect of condition on reasonableness judgments differ by vignette?
To test whether the effect of condition on reasonableness judgments varied by vignette, a model was estimated that included an interaction between vignette and condition (AIC = 4162.6). This model explained more variance than the model without the interaction term. As shown in Figure X, although the general pattern is the same for all vignettes, the magnitudes of differences vary by vignette. Pseudo-R2 values suggest that the interaction between condition and vignette accounts for 1.7% to 7.5% of the random variance in knowledge attributions.
effect
group
term
estimate
std.error
statistic
p.value
fixed
NA
(Intercept)
-2.3791651
0.2891248
-8.2288518
0.0000000
fixed
NA
compensation
-0.1934360
0.0983007
-1.9677995
0.0490911
fixed
NA
age
0.0020431
0.0043646
0.4681024
0.6397114
fixed
NA
gender
0.1333528
0.0927729
1.4374103
0.1506015
fixed
NA
education
-0.0712576
0.0146697
-4.8574782
0.0000012
fixed
NA
condIgnorance
1.1454643
0.2150071
5.3275646
0.0000001
fixed
NA
condKnowledge
-0.0328831
0.2606207
-0.1261723
0.8995955
fixed
NA
vignetteEmma
1.2644499
0.2122467
5.9574542
0.0000000
fixed
NA
vignetteGerald
0.5900779
0.2305366
2.5595845
0.0104797
fixed
NA
condIgnorance:vignetteEmma
-1.1736047
0.2635305
-4.4533917
0.0000085
fixed
NA
condKnowledge:vignetteEmma
-0.6528997
0.3150038
-2.0726722
0.0382028
fixed
NA
condIgnorance:vignetteGerald
-0.6935806
0.2814388
-2.4644106
0.0137239
fixed
NA
condKnowledge:vignetteGerald
-0.0235973
0.3299082
-0.0715270
0.9429783
ran_pars
site
sd__(Intercept)
0.0219121
NA
NA
NA
ran_pars
participant
sd__(Intercept)
0.1085282
NA
NA
NA
ran_pars
vignette
sd__(Intercept)
0.0000000
NA
NA
NA


The likelihood that participants judged the protagonist as reasonable varied by condition in response to the Darrel vignette, χ2(2) = 482.47, p < .001, Emma vignette, χ2(2) = 18.18, p = .001, and Gerald vignette, χ2(2) = 10.16, p = .006. Participants were more likely to judge Darrel to be reasonable in the Gettier condition vignette (0.97) than in the ignorance condition vignette (0.91; Cramer’s V = .12, 95% CI [.08, .17], χ2(1) = 28.46, p < .001), but reasonable judgments did not differ between participants responding to the knowledge and Gettier conditions (Cramer’s V = .00, 95% CI [.02, .02], χ2(1) = 0.00, p = .974). The same pattern of results appeared in response to the Gerald vignette; participants were more likely to judge Gerald as reasonable when responding to the Gettier condition vignette (.94) as opposed to the ignorance condition vignette, (0.91; Cramer’s V = .06, 95% CI [.02, .10], χ22(1) = 5.94, p = .015), but the knowledge and Gettier vignettes produced similar rates of reasonableness judgments, (.94; Cramer’s V = .00, 95% CI [.02, .05], χ2(1) = 0.03, p = .860).
The condition by vignette interaction in predicting judgements of reasonableness appears to have emerged because of the condition differences produced by the Emma vignette. While participants were equally likely to judge Emma as reasonable in the Gettier and ignorance conditions, (Cramer’s V = .00, 95% CI [.02, NA], χ2(1) = 0.00, p = 1.000), participants were more likely to judge Emma as reasonable in response to the knowledge condition vignette (0.94) than in response to the Gettier condition vignette (0.9; Cramer’s V = .09, 95% CI [.05, .13], χ2(1) = 14.31, p < .001). Thus, condition differences were found between the Gettier and ignorance versions of the Darrel and Gerald vignettes, but not the Emma vignette, and between the Gettier and knowledge versions of the Emma vignette, but not the Darrel and Gerald vignettes.
Luck Attributions
As another secondary dependent measure, attributions of luck were predicted in a series of multilevel logistic regressions models. [Two part question & Exclusions from analyses]. We analyzed responses originally reported on continuous and binary scales together; attributions that correct/incorrect identification of the counterfeit target was due to luck were coded as 0 and attributions to (in)ability were coded as 1. Models were fit using the same approach as was employed for the previously described analyses. Compared to the baseline intercept-only model (AIC = 11590.08), a model with a random intercept for vignette (AIC = 10935.66) explained more variance. The likelihood that outcomes were attributed to luck varied according to vignette, with Pseudo-R2 values indicating that vignette accounted for 7.9% to 9.5% of the random variance. While the Darrel vignette produced more attributions to ability than luck, the Emma vignette produced more attributions to luck than ability.
effect
group
term
estimate
std.error
statistic
p.value
fixed
NA
(Intercept)
-0.0670733
0.3392023
-0.1977383
0.8432498
ran_pars
vignette
sd__(Intercept)
0.5861827
NA
NA
NA

 
A model with a random intercept for vignette nested within participant (AIC = 10937.66) explained similar amounts of variance to a model with a random intercept for vignette alone (Pseudo-R2 = .079 - .095). The model with a random intercept for vignette nested in participant nested in data collection (AIC = 10939.67) accounted for the same proportion of random variance; thus, data collection was not retained in subsequent models. Next, covariates were added to the model as fixed effects (AIC = 10799.94). Relative to the model without covariates, this model explained more variance in luck/ability attributions. Years of education emerged as a significant predictor; as participant education increased, the likelihood they would attribute the protagonist’s success to luck decreased (3% per edu year).
effect
group
term
estimate
std.error
statistic
p.value
fixed
NA
(Intercept)
0.3570721
0.3656382
0.9765724
0.3287809
fixed
NA
compensation
-0.0981989
0.0544703
-1.8027959
0.0714203
fixed
NA
age
0.0031681
0.0023632
1.3406324
0.1800398
fixed
NA
gender
-0.0502110
0.0502387
-0.9994483
0.3175776
fixed
NA
education
-0.0293869
0.0087987
-3.3398975
0.0008381
ran_pars
site
sd__(Intercept)
0.0000133
NA
NA
NA
ran_pars
participant
sd__(Intercept)
0.0000530
NA
NA
NA
ran_pars
vignette
sd__(Intercept)
0.5872439
NA
NA
NA

 
Finally, we estimated a model including condition as a fixed effect (AIC = 10460.18). This model performed better than the previous one; the likelihood of luck attributions differed according to condition, which accounted for 4.3% to 5.1% of the fixed effect variance. Participants were more likely to attribute the outcome to luck in the Gettier condition than in the other two conditions (see Table X). Thus, in  response to both the knowledge condition and the ignorance condition, participants were more likely to attribute outcomes to the protagonist’s ability than to luck, but they were more likely to make luck attributions than ability attributions in response to the Gettier condition vignette.
effect
group
term
estimate
std.error
statistic
p.value
fixed
NA
(Intercept)
-0.2397528
0.3815966
-0.6282885
0.5298150
fixed
NA
compensation
-0.1013198
0.0557092
-1.8187263
0.0689532
fixed
NA
age
0.0033878
0.0024156
1.4024716
0.1607745
fixed
NA
gender
-0.0546312
0.0513360
-1.0641871
0.2872439
fixed
NA
education
-0.0310176
0.0089733
-3.4566611
0.0005469
fixed
NA
condIgnorance
0.9365112
0.0582148
16.0871626
0.0000000
fixed
NA
condKnowledge
0.9039315
0.0581048
15.5569244
0.0000000
ran_pars
site
sd__(Intercept)
0.0586139
NA
NA
NA
ran_pars
participant
sd__(Intercept)
0.0999593
NA
NA
NA
ran_pars
vignette
sd__(Intercept)
0.6125805
NA
NA
NA

Does the effect of condition on luck attributions differ by vignette?
To better understand whether the effect of condition on luck attributions varied as a function of vignette, we estimated a model including an interaction between vignette and condition (AIC = 10172.3). This model explained more variance than the model without the interaction. Pseudo-R2 values suggest that the interaction between condition and vignette accounted for 18.9% to 22.1% of the random variance in luck attributions. As shown in Figure X, each vignette demonstrated a different pattern of effects.
effect
group
term
estimate
std.error
statistic
p.value
fixed
NA
(Intercept)
0.8555357
0.1547862
5.5272097
0.0000000
fixed
NA
compensation
-0.0989522
0.0565280
-1.7505006
0.0800320
fixed
NA
age
0.0033054
0.0024503
1.3489871
0.1773411
fixed
NA
gender
-0.0812981
0.0520098
-1.5631308
0.1180218
fixed
NA
education
-0.0288652
0.0091234
-3.1638829
0.0015568
fixed
NA
condIgnorance
0.0152101
0.0963262
0.1579021
0.8745339
fixed
NA
condKnowledge
0.7210635
0.1022916
7.0490949
0.0000000
fixed
NA
vignetteEmma
-2.8257731
0.1356815
-20.8265182
0.0000000
fixed
NA
vignetteGerald
-1.0239035
0.0966656
-10.5922250
0.0000000
fixed
NA
condIgnorance:vignetteEmma
2.5089732
0.1662712
15.0896441
0.0000000
fixed
NA
condKnowledge:vignetteEmma
1.0095409
0.1707987
5.9107049
0.0000000
fixed
NA
condIgnorance:vignetteGerald
0.7020052
0.1352674
5.1897605
0.0000002
fixed
NA
condKnowledge:vignetteGerald
0.0644849
0.1403821
0.4593530
0.6459807
ran_pars
site
sd__(Intercept)
0.0001054
NA
NA
NA
ran_pars
participant
sd__(Intercept)
0.0207679
NA
NA
NA
ran_pars
vignette
sd__(Intercept)
0.0000000
NA
NA
NA

 

The likelihood that participants attributed the outcome in the Darrel vignette to luck differed according to condition, χ2(2) = 62.99, p < .001. While participants were equally likely to report luck attributions in response to the ignorance and Gettier conditions of the Darrel vignette (Cramer’s V = .00, 95% CI [.02, .04], χ2(1) = 0.00, p = .947), participants were less likely to attribute Darrel’s identification to luck in the knowledge condition (0.24) than in the Gettier condition (0.39; Cramer’s V = .16, 95% CI [.12, .21], χ2(1) = 49.27, p < .001).
The likelihood of luck attributions also varied by condition matched with the Emma vignette, χ2(2) = 431.92, p < .001. Participants were more likely to attribute Emma’s identification to luck in response to the Gettier condition (0.92) than in response to the ignorance condition (0.47; Cramer’s V = .49, 95% CI [.44, .53], χ2(1) = 435.54, p < .001). Further, participants were less likely to attribute the outcome of the Emma vignette to luck in the knowledge condition (0.66) than in the Gettier condition (0.92; Cramer’s V = .31, 95% CI [.27, .36], χ2(1) = 182.41, p < .001).
The likelihood of luck attributions also differed according to the Gerald vignette condition,  χ2(2) = 382.75, p < .001.  Participants were more likely to attribute luck in response to the Gettier condition (0.92) than to the ignorance condition (0.47; Cramer’s V = .18, 95% CI [.13, .22], χ2(1) = 56.82, p < .001). Participants were less likely to attribute Gerald’s identification to luck in the knowledge condition (0.66) than in the Gettier condition (Cramer’s V = .19, 95% CI [.15, .24], χ2(1) = 66.72, p < .001). Thus, seemingly, the vignette by condition interaction was driven by responses to the Gettier condition:  The difference in likelihoods of luck attributions between the Gettier and ignorance conditions was absent for the Darrel vignette, moderate for the Gerald vignette, and large for the Emma vignette.
Moderation Effects
Participant Recruitment
Because data was collected from MTurk workers as well as participants recruited from individual labs, we explored whether participant recruitment moderated the effect of condition on knowledge attributions and the other two dependent measures. The main effect of participant source and the interaction between source and condition was added to the model including the covariates and condition. Though this model was superior (AIC = 9663.25) to the one without the interaction, the interaction term was not a significant predictor of knowledge attributions. Then, we estimated a model that included an interaction between condition and recruitment type predicting judgments of reasonableness (AIC = 4162.22). While this model performed better than a model without the interaction, the interaction between condition and recruitment type was not significant. Finally, we estimated a model that included an interaction between condition and recruitment type in predicting luck attributions (AIC = 10434.61). This model performed better than a model without the interaction. However, as with models predicting knowledge attributions and reasonableness, the interaction between condition and recruitment type was not significant. Thus, the effect of condition differed as a function of how participants were recruited for any of the dependent measures.
Measurement Characteristics
Knowledge Atts -> We also examined whether condition effects were influenced by measurement characteristics, specifically if the outcome was originally measured on a binary or visual analogue scale. Adding measurement and its interaction with condition to the model did not improve model fit (AIC = 9692.92); thus, we found no evidence for moderation.
Reason -> Then, we estimated a model that included an interaction between condition and measurement type (AIC = 4182.04), but this model did not perform better than a model without the interaction. Thus, we found no evidence that the effect of condition differed as a function of how participants were recruited or how reasonableness judgments were measured.
Finally, we estimated a model that included an interaction between condition and measurement type predicting luck attributions (AIC = 10434.66). This model performed better than a model without the condition by measurement type interaction. As shown in Figure X, the effect of condition was consistent across measurement type but appears to differ in magnitude.

Condition affected the likelihood of luck attributions on responses to the binary measure, χ2(2) = 87.12, p <.0001. Participants were more likely to attribute outcomes to luck in the Gettier condition (0.64) than in the ignorance condition (0.32; Cramer’s V = .32, 95% CI [.25, .39], χ2(1) = 81.44, p < .001). Participants were also more likely to attribute outcomes to luck in the Gettier condition (0.64) than in the knowledge condition (0.42; Cramer’s V = .22, 95% CI [.15, .29], χ2(1) = 38.57, p < .001). Condition similarly affected luck attributions as measured by the VAS,
χ2(2) = 243.47, p < .001. Participants were more likely to attribute outcomes to luck in the Gettier condition (0.65) than in the ignorance condition (0.46; Cramer’s V = .19, 95% CI [.16, .22], χ2(1) = 174.33, p < .001). Participants were also more likely to attribute outcomes to luck in the Gettier condition (0.65) than in the knowledge condition (0.45; Cramer’s V = .20, 95% CI [.17, .23], χ2(1) = 191.99, p < .001). Effect sizes were smaller when luck was measured continuously, but the confidence intervals of these effect sizes overlapped with those produced by the binary measure.
Exploratory Analyses
In addition to the hypotheses and research questions outlined in the approved protocol, we conducted additional exploratory analyses to explore two additional research questions.
First, we conducted analyses to assess whether question wording affects people’s knowledge attributions. 
Prior research has demonstrated that the way in which participants attribute knowledge may depend on how they are asked whether a target has knowledge (e.g., “does the target know?” vs. “does the target know, or do they only feel like they know?”; e.g., Machery et al., 2017; Nagel et al., 2013). For example, Machery et al. (2017) asked participants to respond to two different knowledge probes: one that asked whether the protagonist knew or did not know (Knowledge 1) and another that asked whether the protagonist knew or only thought they knew but did not know (Knowledge 2). Across the 24 collection sites in their study, Gettier intuitions were demonstrated for only 11 sites on the Knowledge 1 probe while all but one of the sites demonstrated Gettier intuitions on the Knowledge 2 probe - indicating that people are more likely to deny knowledge to a protagonist when they are asked a more nuanced question about knowledge. To evaluate whether asking participants to attribute knowledge in a more nuanced way produces different results, we asked an alternative knowledge question previously used by Nagel et al. (2013) after each presented vignette. [Fill in a rationale here.]
Second, we conducted analyses to assess whether people’s perceptions of luck inform their knowledge attributions. Prior work has suggested that perceptions of luck moderate the extent to which Gettier intuitions are demonstrated (Turri, 2016; 2017). For example, Turri (2016; Experiment 7) found that 1) participants’ knowledge attributions and luck/ability attributions were significantly positively correlated (r = .622, p < .001) and that 2) participants were considerably less likely to attribute knowledge to a protagonist that was perceived as having arrived at a truth because of a lucky guess compared to a protagonist that was perceived as having arrived at the truth because of their ability (ηp2 = .353). To test this hypothesized moderation effect, we tested a model that included an interaction between luck attributions and condition on a model predicting knowledge attributions. 
 
 
