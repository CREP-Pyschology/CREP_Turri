---
title: "Reviewer Comment Discussion"
author: "Erin M. Buchanan"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    depth: 4
    toc_float:
      collapsed: false
      smooth_scroll: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

# Libraries

```{r}
library(dplyr)
library(ggplot2)
library(lme4)
library(lmerTest)
library(flextable)
library(rio)
library(ggmosaic)
options(scipen = 10)
```

# Import Data

```{r}
load("linear_exclude.Rdata")
linear_exclude <- output

load("linear_noexclude.Rdata")
linear_no <- output

load("log_exclude.Rdata")
log_exclude <- output

load("log_noexclude.Rdata")
log_no <- output

rm(output)

load("final_long_log_noexclude.Rdata")
load("final_luck_log_noexclude.Rdata")
lab_sheet <- import("lab_sheet_un_region_update.csv")
```

# Modeling Comparison

In this section, we examine two questions:

- The impact of the change in exclusion criteria: we *included* all CREP teams that at least were approved and *excluded* those who marked age as over 100 as unlikely numbers. 
- The impact of dichotomization: data screening results indicated that the model was not linear, and we dichotomized the data. 
- We ran all four combinations of these two variables to examine the results. 

## Data Screening

- In order to explain why we made the decision to split the data, we examined data screening on Model 6 with all random intercepts, covariates, and the main effect of condition. Each of these is provided below. Click *view data screening* to view the outputs. 
- As shown in the data screening, the linear model does not meet the assumptions of normality, linearity, or homoscedasticity. Given the previous study was binary and a visual inspection of the data showed a u-shaped distribution, we choose to dichotomize the data. The logistic regression data screening shows that the assumptions of additivity and linearity of the logit for continuous predictors was met. 

### Linear, Pre-registered Exclusions

<details><summary>View data screening</summary>

```{r}
# additivity
round(cov2cor(vcov(linear_no[[5]])),2)

# normality
standardized <- residuals(linear_no[[5]], type = "pearson")
hist(standardized) 

# linearity
{qqnorm(standardized)
  abline(0,1)}

# homosc
fitted <- scale(fitted.values(linear_no[[5]]))
{plot(fitted, standardized)
  abline(v = 0)
  abline(h = 0)}
```

</details>

### Linear, New Exclusions

<details><summary>View data screening</summary>

```{r}
# additivity
round(cov2cor(vcov(linear_exclude[[5]])),2)

# normality
standardized <- residuals(linear_exclude[[5]], type = "pearson")
hist(standardized) 

# linearity
{qqnorm(standardized)
  abline(0,1)}

# homosc
fitted <- scale(fitted.values(linear_exclude[[5]]))
{plot(fitted, standardized)
  abline(v = 0)
  abline(h = 0)}
```

</details>

### Logistic, Pre-registered Exclusions

<details><summary>View data screening</summary>

```{r}
# additivity
round(cov2cor(vcov(log_no[[6]])),2)

# linearity logit
df <- log_no[[6]]@frame
df$probs <- predict(log_no[[6]], type = "response")
df$logit <- log(df$probs/(1-df$probs))

ggplot(df, aes(logit, age)) + 
  geom_point() + 
  theme_classic() + 
  geom_smooth(method = "lm") + 
  facet_wrap(~vignette*cond)


ggplot(df, aes(logit, education)) + 
  geom_point() + 
  theme_classic() + 
  geom_smooth(method = "lm") + 
  facet_wrap(~vignette*cond)
```

</details>

### Logistic, New Exclusions (Paper)

<details><summary>View data screening</summary>

```{r}
# additivity
round(cov2cor(vcov(log_exclude[[6]])),2)

# linearity logit
df <- log_exclude[[6]]@frame
df$probs <- predict(log_exclude[[6]], type = "response")
df$logit <- log(df$probs/(1-df$probs))

ggplot(df, aes(logit, age)) + 
  geom_point() + 
  theme_classic() + 
  geom_smooth(method = "lm") + 
  facet_wrap(~vignette*cond)


ggplot(df, aes(logit, education)) + 
  geom_point() + 
  theme_classic() + 
  geom_smooth(method = "lm") + 
  facet_wrap(~vignette*cond)
```

</details> 

## Overall Model Comparison

1) Intercept only model DV ~ 1
2) Intercept model with random intercept vignette
3) Intercept model with random intercept vignette/participant id, no linear model, would not converge 
4) Intercept model with random intercept vignette/id/lab, for the linear model no participant id was used 
5) Random intercepts and covariates
6) Random intercepts, covariates, and condition
6a) Random intercepts, covariates, and condition by vignette
6b) Random intercepts, covariates, and condition by turk

- These results are discussed below within each dependent variable; however, the general summary is the same for each:
  - Covariate models are all better (model 5 < model 4)
  - Condition adds to model (model 6)
  - Interaction add to model (model 6a)
  - Turk add to model (model 6b)
- Therefore, all model decisions would be the same given different versions of exclusions or linking functions. 

```{r}
linear_e_AIC <- unlist(lapply(linear_exclude, AIC))
linear_n_AIC <- unlist(lapply(linear_no, AIC))
log_e_AIC <- unlist(lapply(log_exclude, AIC))
log_n_AIC <- unlist(lapply(log_no, AIC))

log_aics <- data.frame(
  "model" = c("know1", "know2", "know3", "know4", "know5", "know6", "know6a", "know6b", 
            "reason1", "reason2", "reason3", "reason4", "reason5", "reason6", "reason6a", "reason6b", 
            "luck1", "luck2", "luck3", "luck4", "luck5", "luck6", "luck6a", "luck6b"),
  "log_e_AIC" = log_e_AIC, 
  "log_n_AIC" = log_n_AIC
)

linear_aics <- data.frame(
  "model" = c("know1", "know2", "know4", "know5", "know6", "know6a", "know6b", 
            "reason1", "reason2", "reason4", "reason5", "reason6", "reason6a", "reason6b", 
            "luck1", "luck2", "luck4", "luck5", "luck6", "luck6a", "luck6b"),
  "linear_e_AIC" = linear_e_AIC, 
  "linear_n_AIC" = linear_n_AIC
)

aics <- log_aics %>% 
  full_join(linear_aics, 
            by = "model")

flextable(aics)
```

## Knowledge

### Condition

- Complete output can be seen below. 
- In logistic versus linear: we find the same pattern of results for the condition variable - we cannot compare these directly because they are on different scales, however, they provide the same direction and significance decisions.
- In exclusions: both provide the same results within the same confidence intervals, directions, and significance decisions. 

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[6]])

# log pre-registered exclusions
summary(log_no[[6]])

# linear updated exclusions
summary(linear_exclude[[5]])

# linear pre-registered exclusions
summary(linear_no[[5]])
```

</details> 

### Vignette

- Logistic versus linear: Both show significant interactions between condition and vignette. 
- Exclusions: Both show significant interactions between condition and vignette. 
- The exact pattern of these interactions is different within predictors but generally has the same pattern of results. 

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[7]])

# log pre-registered exclusions
summary(log_no[[7]])

# linear updated exclusions
summary(linear_exclude[[6]])

# linear pre-registered exclusions
summary(linear_no[[6]])
```

</details> 

### Turk

- Logistic versus linear: In this case, logistic models do not show an interaction between the Turk sample and the condition. Linear models show an interaction. 
- Exclusions: exclusions do not appear to change the pattern of results within each linking function. 
- The effect for linear models is graphed below. This result occurs because there is slightly more sensitivity to show the differences between Gettier and Knowledge in Turk than the other sample. A visualization of the distributions shows that more people pick zero in the regular sample than Turk. 

<details><summary>View full result</summary>

```{r}
# log updated exclusions
summary(log_exclude[[8]])

# log pre-registered exclusions
summary(log_no[[8]])

# linear updated exclusions
summary(linear_exclude[[7]])

# linear pre-registered exclusions
summary(linear_no[[7]])
```

</details> 

```{r}
df <- linear_exclude[[7]]@frame

ggplot(df, aes(turk, know_vas, fill = cond)) +
  stat_summary(fun = mean,
               geom = "bar",
               position = "dodge") +
  stat_summary(fun.data = mean_cl_normal,
               geom = "errorbar", 
               position = position_dodge(width = 0.90),
               width = .2) + 
  theme_classic() + 
  xlab("Turk Sample") + 
  ylab("Knowledge Rating") + 
  scale_fill_discrete(name = "Condition")

ggplot(df, aes(turk, know_vas)) + 
  geom_violin() + 
  theme_classic() + 
  xlab("Turk Sample") + 
  ylab("Knowledge Rating")
```

## Reasonable

### Condition

- Logistic versus linear: The pattern, direction, and magnitude of results is the same. 
- Exclusions: The pattern, direction, and magnitude of results is the same. 

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[14]])

# log pre-registered exclusions
summary(log_no[[14]])

# linear updated exclusions
summary(linear_exclude[[12]])

# linear pre-registered exclusions
summary(linear_no[[12]])
```

</details> 

### Vignette

- Logistic versus linear: Generally, each version showed an interaction of condition and vignette. 
- Exclusions: Logistic models both showed interactions for each exclusion type. However, the linear model with the pre-registered exclusions did not show an interaction between condition and vignette. This model has significantly less power than the updated exclusions, as only has 8000 data points (~2600+ participants) versus 12000 + data points (~4100+ participants). 

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[15]])

# log pre-registered exclusions
summary(log_no[[15]])

# linear updated exclusions
summary(linear_exclude[[13]])

# linear pre-registered exclusions
summary(linear_no[[13]])
```

</details> 

### Turk 

- Logistic versus linear: Generally, this shows the same pattern, direction, and magnitude of results. 
- Exclusions: Given the dichotomization of p-values, the linear model with pre-registered exclusions does show one significant interaction between Turk and condition. However, the estimates each overlap within confidence interval, magnitude, and direction. 

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[16]])

# log pre-registered exclusions
summary(log_no[[16]])

# linear updated exclusions
summary(linear_exclude[[14]])

# linear pre-registered exclusions
summary(linear_no[[14]])
```

</details> 

## Luck

### Condition

- Logistic versus linear: Models show the same results. 
- Exclusions: Models show the same results. 

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[22]])

# log pre-registered exclusions
summary(log_no[[22]])

# linear updated exclusions
summary(linear_exclude[[19]])

# linear pre-registered exclusions
summary(linear_no[[19]])
```

</details> 

### Vignette

- Logistic versus linear: Models show the same pattern of interaction results. 
- Exclusions: Models show the same pattern of interaction results. 

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[23]])

# log pre-registered exclusions
summary(log_no[[23]])

# linear updated exclusions
summary(linear_exclude[[20]])

# linear pre-registered exclusions
summary(linear_no[[20]])
```

</details> 

### Turk 

- Logistic versus linear: All models show no interaction of condition and Turk. 
- Exclusions:  All models show no interaction of condition and Turk.

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[24]])

# log pre-registered exclusions
summary(log_no[[24]])

# linear updated exclusions
summary(linear_exclude[[21]])

# linear pre-registered exclusions
summary(linear_no[[21]])
```

</details> 

# Qualtrics versus SoSciSurvey

```{r}
table(final_long$source, useNA = "ifany")
```

## Knowledge

- No interaction of source and condition results. 

```{r}
k.model.qualtrics <- glmer(know_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*source,
                      data = final_long,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(k.model.qualtrics)
```

## Reasonable

- Interaction of source and condition results - in general, Qualtrics participants tend to pick reasonable more often but the pattern of choices relative to other conditions is the same. 

```{r}
r.model.qualtrics <- glmer(reason_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*source,
                      data = final_long,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(r.model.qualtrics)

df <- r.model.qualtrics@frame

df$reason_vas_combined <- factor(df$reason_vas_combined,
                                 levels = c(0,1),
                                 labels = c("Unreasonable", "Reasonable"))

ggplot(df) +
  geom_mosaic(aes(x = product(reason_vas_combined, source, cond), 
                  fill = reason_vas_combined), color = "black", size = .5) + 
  scale_fill_brewer(palette = "Greys", name = "Reason Choice", 
                    direction = -1) + 
  scale_x_productlist(breaks = c(0.13,.5,.87),
    labels = c("Gettier", "Ignorance", "Knowledge")) +
  theme_classic() + 
  xlab("Condition") + 
  ylab("Source")
```

## Luck 

- No interaction with luck. 

```{r}
l.model.qualtrics <- glmer(luck_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*source,
                      data = final_luck,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(l.model.qualtrics)
```