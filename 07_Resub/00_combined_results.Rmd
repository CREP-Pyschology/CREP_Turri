---
title: "Reviewer Comment Discussion"
author: "Erin M. Buchanan"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    depth: 4
    toc_float:
      collapsed: false
      smooth_scroll: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

# Libraries

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(lme4)
library(lmerTest)
library(flextable)
library(rio)
library(ggmosaic)
library(kableExtra)
library(maps)
library(countrycode)
library(treemapify)
library(MOTE)
library(broom)
options(scipen = 10)
```

# Import Data

```{r}
load("linear_exclude.Rdata")
linear_exclude <- output

load("linear_noexclude.Rdata")
linear_no <- output

load("log_exclude.Rdata")
log_exclude <- output

load("log_noexclude.Rdata")
log_no <- output

rm(output)

load("final_long_log_exclude.Rdata")
load("final_luck_log_exclude.Rdata")
lab_sheet <- import("lab_sheet_un_region_update.csv")

load("full_long_log_exclude.Rdata")
```

# Modeling Comparison

In this section, we examine two questions:

- The impact of the change in exclusion criteria: we *included* all CREP teams that at least were approved and *excluded* those who marked age as over 100 as unlikely numbers. 
- The impact of dichotomization: data screening results indicated that the model was not linear, and we dichotomized the data. 
- We ran all four combinations of these two variables to examine the results. 

## Data Screening

- In order to explain why we made the decision to split the data, we examined data screening on Model 6 with all random intercepts, covariates, and the main effect of condition. Each of these is provided below. Click *view data screening* to view the outputs. 
- As shown in the data screening, the linear model does not meet the assumptions of normality, linearity, or homoscedasticity. Given the previous study was binary and a visual inspection of the data showed a u-shaped distribution, we choose to dichotomize the data. The logistic regression data screening shows that the assumptions of additivity and linearity of the logit for continuous predictors was met. 

### Linear, Pre-registered Exclusions

<details><summary>View data screening</summary>

```{r}
# additivity
round(cov2cor(vcov(linear_no[[5]])),2)

# normality
standardized <- residuals(linear_no[[5]], type = "pearson")
hist(standardized) 

# linearity
{qqnorm(standardized)
  abline(0,1)}

# homosc
fitted <- scale(fitted.values(linear_no[[5]]))
{plot(fitted, standardized)
  abline(v = 0)
  abline(h = 0)}
```

</details>

### Linear, New Exclusions

<details><summary>View data screening</summary>

```{r}
# additivity
round(cov2cor(vcov(linear_exclude[[5]])),2)

# normality
standardized <- residuals(linear_exclude[[5]], type = "pearson")
hist(standardized) 

# linearity
{qqnorm(standardized)
  abline(0,1)}

# homosc
fitted <- scale(fitted.values(linear_exclude[[5]]))
{plot(fitted, standardized)
  abline(v = 0)
  abline(h = 0)}
```

</details>

### Logistic, Pre-registered Exclusions

<details><summary>View data screening</summary>

```{r}
# additivity
round(cov2cor(vcov(log_no[[6]])),2)

# linearity logit
df <- log_no[[6]]@frame
df$probs <- predict(log_no[[6]], type = "response")
df$logit <- log(df$probs/(1-df$probs))

ggplot(df, aes(logit, age)) + 
  geom_point() + 
  theme_classic() + 
  geom_smooth(method = "lm") + 
  facet_wrap(~vignette*cond)


ggplot(df, aes(logit, education)) + 
  geom_point() + 
  theme_classic() + 
  geom_smooth(method = "lm") + 
  facet_wrap(~vignette*cond)
```

</details>

### Logistic, New Exclusions (Paper)

<details><summary>View data screening</summary>

```{r}
# additivity
round(cov2cor(vcov(log_exclude[[6]])),2)

# linearity logit
df <- log_exclude[[6]]@frame
df$probs <- predict(log_exclude[[6]], type = "response")
df$logit <- log(df$probs/(1-df$probs))

ggplot(df, aes(logit, age)) + 
  geom_point() + 
  theme_classic() + 
  geom_smooth(method = "lm") + 
  facet_wrap(~vignette*cond)


ggplot(df, aes(logit, education)) + 
  geom_point() + 
  theme_classic() + 
  geom_smooth(method = "lm") + 
  facet_wrap(~vignette*cond)
```

</details> 

## Overall Model Comparison

1) Intercept only model DV ~ 1
2) Intercept model with random intercept vignette
3) Intercept model with random intercept vignette/participant id, no linear model, would not converge 
4) Intercept model with random intercept vignette/id/lab, for the linear model no participant id was used 
5) Random intercepts and covariates
6) Random intercepts, covariates, and condition
6a) Random intercepts, covariates, and condition by vignette
6b) Random intercepts, covariates, and condition by turk

- These results are discussed below within each dependent variable; however, the general summary is the same for each:
  - Covariate models are all better (model 5 < model 4)
  - Condition adds to model (model 6)
  - Interaction add to model (model 6a)
  - Turk add to model (model 6b)
- Therefore, all model decisions would be the same given different versions of exclusions or linking functions. 

```{r}
linear_e_AIC <- unlist(lapply(linear_exclude, AIC))
linear_n_AIC <- unlist(lapply(linear_no, AIC))
log_e_AIC <- unlist(lapply(log_exclude, AIC))
log_n_AIC <- unlist(lapply(log_no, AIC))

log_aics <- data.frame(
  "model" = c("know1", "know2", "know3", "know4", "know5", "know6", "know6a", "know6b", 
            "reason1", "reason2", "reason3", "reason4", "reason5", "reason6", "reason6a", "reason6b", 
            "luck1", "luck2", "luck3", "luck4", "luck5", "luck6", "luck6a", "luck6b"),
  "log_e_AIC" = log_e_AIC, 
  "log_n_AIC" = log_n_AIC
)

linear_aics <- data.frame(
  "model" = c("know1", "know2", "know4", "know5", "know6", "know6a", "know6b", 
            "reason1", "reason2", "reason4", "reason5", "reason6", "reason6a", "reason6b", 
            "luck1", "luck2", "luck4", "luck5", "luck6", "luck6a", "luck6b"),
  "linear_e_AIC" = linear_e_AIC, 
  "linear_n_AIC" = linear_n_AIC
)

aics <- log_aics %>% 
  full_join(linear_aics, 
            by = "model")

flextable(aics)
```

## Knowledge

### Condition

- Complete output can be seen below. 
- In logistic versus linear: we find the same pattern of results for the condition variable - we cannot compare these directly because they are on different scales, however, they provide the same direction and significance decisions.
- In exclusions: both provide the same results within the same confidence intervals, directions, and significance decisions. 

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[6]])

# log pre-registered exclusions
summary(log_no[[6]])

# linear updated exclusions
summary(linear_exclude[[5]])

# linear pre-registered exclusions
summary(linear_no[[5]])
```

</details> 

### Vignette

- Logistic versus linear: Both show significant interactions between condition and vignette. 
- Exclusions: Both show significant interactions between condition and vignette. 
- The exact pattern of these interactions is different within predictors but generally has the same pattern of results. 

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[7]])

# log pre-registered exclusions
summary(log_no[[7]])

# linear updated exclusions
summary(linear_exclude[[6]])

# linear pre-registered exclusions
summary(linear_no[[6]])
```

</details> 

### Turk

- Logistic versus linear: In this case, logistic models do not show an interaction between the Turk sample and the condition. Linear models show an interaction. 
- Exclusions: exclusions do not appear to change the pattern of results within each linking function. 
- The effect for linear models is graphed below. This result occurs because there is slightly more sensitivity to show the differences between Gettier and Knowledge in Turk than the other sample. A visualization of the distributions shows that more people pick zero in the regular sample than Turk. 

<details><summary>View full result</summary>

```{r}
# log updated exclusions
summary(log_exclude[[8]])

# log pre-registered exclusions
summary(log_no[[8]])

# linear updated exclusions
summary(linear_exclude[[7]])

# linear pre-registered exclusions
summary(linear_no[[7]])
```

</details> 

```{r}
df <- linear_exclude[[7]]@frame

ggplot(df, aes(turk, know_vas, fill = cond)) +
  stat_summary(fun = mean,
               geom = "bar",
               position = "dodge") +
  stat_summary(fun.data = mean_cl_normal,
               geom = "errorbar", 
               position = position_dodge(width = 0.90),
               width = .2) + 
  theme_classic() + 
  xlab("Turk Sample") + 
  ylab("Knowledge Rating") + 
  scale_fill_discrete(name = "Condition")

ggplot(df, aes(turk, know_vas)) + 
  geom_violin() + 
  theme_classic() + 
  xlab("Turk Sample") + 
  ylab("Knowledge Rating")
```

## Reasonable

### Condition

- Logistic versus linear: The pattern, direction, and magnitude of results is the same. 
- Exclusions: The pattern, direction, and magnitude of results is the same. 

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[14]])

# log pre-registered exclusions
summary(log_no[[14]])

# linear updated exclusions
summary(linear_exclude[[12]])

# linear pre-registered exclusions
summary(linear_no[[12]])
```

</details> 

### Vignette

- Logistic versus linear: Generally, each version showed an interaction of condition and vignette. 
- Exclusions: Logistic models both showed interactions for each exclusion type. However, the linear model with the pre-registered exclusions did not show an interaction between condition and vignette. This model has significantly less power than the updated exclusions, as only has 8000 data points (~2600+ participants) versus 12000 + data points (~4100+ participants). 

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[15]])

# log pre-registered exclusions
summary(log_no[[15]])

# linear updated exclusions
summary(linear_exclude[[13]])

# linear pre-registered exclusions
summary(linear_no[[13]])
```

</details> 

### Turk 

- Logistic versus linear: Generally, this shows the same pattern, direction, and magnitude of results. 
- Exclusions: Given the dichotomization of p-values, the linear model with pre-registered exclusions does show one significant interaction between Turk and condition. However, the estimates each overlap within confidence interval, magnitude, and direction. 

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[16]])

# log pre-registered exclusions
summary(log_no[[16]])

# linear updated exclusions
summary(linear_exclude[[14]])

# linear pre-registered exclusions
summary(linear_no[[14]])
```

</details> 

## Luck

### Condition

- Logistic versus linear: Models show the same results. 
- Exclusions: Models show the same results. 

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[22]])

# log pre-registered exclusions
summary(log_no[[22]])

# linear updated exclusions
summary(linear_exclude[[19]])

# linear pre-registered exclusions
summary(linear_no[[19]])
```

</details> 

### Vignette

- Logistic versus linear: Models show the same pattern of interaction results. 
- Exclusions: Models show the same pattern of interaction results. 

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[23]])

# log pre-registered exclusions
summary(log_no[[23]])

# linear updated exclusions
summary(linear_exclude[[20]])

# linear pre-registered exclusions
summary(linear_no[[20]])
```

</details> 

### Turk 

- Logistic versus linear: All models show no interaction of condition and Turk. 
- Exclusions:  All models show no interaction of condition and Turk.

<details><summary>View full results</summary>

```{r}
# log updated exclusions
summary(log_exclude[[24]])

# log pre-registered exclusions
summary(log_no[[24]])

# linear updated exclusions
summary(linear_exclude[[21]])

# linear pre-registered exclusions
summary(linear_no[[21]])
```

</details> 

# Qualtrics versus SoSciSurvey

- This section examines if there is an interaction between data collection source (Qualtrics versus SoSciSurvey) and the results with condition. 

```{r}
table(final_long$source, useNA = "ifany")
```

## Knowledge

- No interaction of source and condition results. 

<details><summary>View full results</summary>

```{r}
k.model.qualtrics <- glmer(know_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*source,
                      data = final_long,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(k.model.qualtrics)
```

</details>

## Reasonable

- No interaction of source of data collection and condition. 

<details><summary>View full results</summary>

```{r}
r.model.qualtrics <- glmer(reason_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*source,
                      data = final_long,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(r.model.qualtrics)
```

</details>

## Luck 

- No interaction of the survey programming with luck as the dependent variable. 

<details><summary>View full results</summary>

```{r}
l.model.qualtrics <- glmer(luck_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*source,
                      data = final_luck,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(l.model.qualtrics)
```

</details>

# Table of Exclusions by Vignette and Condition

- Exclusions if one considered each comprehension check separately. 

```{r}
# 1 is right 2 is wrong for GK 
# 1 is wrong 2 is right for I
full_long$correct <- NA
full_long$correct[full_long$cond == "Ignorance" & full_long$compr == "2"] <- TRUE
full_long$correct[full_long$cond == "Ignorance" & full_long$compr == "1"] <- FALSE
full_long$correct[full_long$cond != "Ignorance" & full_long$compr == "1"] <- TRUE
full_long$correct[full_long$cond != "Ignorance" & full_long$compr == "2"] <- FALSE

flextable(full_long %>% 
            group_by(vignette, cond, correct) %>% 
            select(vignette, cond, correct) %>% 
            drop_na() %>% 
            count())
```

# Only Exclude For Condition Incorrect

- The first results presented in each section are analyses wherein each section excludes only the vignettes that were answered correctly, and the second summary is the original information presented in the manuscript. 

```{r}
# data prep
exclude_DF <- full_long %>% 
  filter(correct == TRUE) %>% 
  filter(age_exclusion == FALSE) %>% 
  filter(previous_exclusion == FALSE) %>% 
  filter(purpose_exclusion == FALSE) %>% 
  filter(lang_exclusion == FALSE)

nrow(exclude_DF)
length(unique(exclude_DF$id))
length(unique(exclude_DF$person_code))

# full data
table(full_long$vignette, full_long$cond, useNA = "ifany")
# exclude based on incorrect answers 
table(exclude_DF$vignette, exclude_DF$cond, useNA = "ifany")

# knowledge recode
exclude_DF$know_vas_binned <- exclude_DF$know_vas
exclude_DF$know_vas_binned[exclude_DF$know_vas_binned <= 40] <- 2
exclude_DF$know_vas_binned[exclude_DF$know_vas_binned > 40 & 
                             exclude_DF$know_vas_binned < 60] <- NA
exclude_DF$know_vas_binned[exclude_DF$know_vas_binned >= 60] <- 1
exclude_DF$know_vas_combined <- ifelse(is.na(exclude_DF$know_vas_binned), 
                                     exclude_DF$know_bin, 
                                     exclude_DF$know_vas_binned)

exclude_DF$know_vas_combined <- 3 - exclude_DF$know_vas_combined

# reason recode
exclude_DF$reason_vas_binned <- exclude_DF$reason_vas
exclude_DF$reason_vas_binned[exclude_DF$reason_vas_binned <= 40] <- 2
exclude_DF$reason_vas_binned[exclude_DF$reason_vas_binned > 40 & 
                             exclude_DF$reason_vas_binned < 60] <- NA
exclude_DF$reason_vas_binned[exclude_DF$reason_vas_binned >= 60] <- 1
exclude_DF$reason_vas_combined <- ifelse(is.na(exclude_DF$reason_vas_binned), 
                                     exclude_DF$reason_bin, 
                                     exclude_DF$reason_vas_binned)

exclude_DF$reason_vas_combined <- 3 - exclude_DF$reason_vas_combined

# luck recode
exclude_DF$luck_vas_binned <- exclude_DF$luck_vas
exclude_DF$luck_vas_binned[exclude_DF$luck_vas_binned <= 40] <- 2
exclude_DF$luck_vas_binned[exclude_DF$luck_vas_binned > 40 & 
                             exclude_DF$luck_vas_binned < 60] <- NA
exclude_DF$luck_vas_binned[exclude_DF$luck_vas_binned >= 60] <- 1
exclude_DF$luck_vas_combined <- ifelse(is.na(exclude_DF$luck_vas_binned), 
                                     exclude_DF$luck_bin, 
                                     exclude_DF$luck_vas_binned)

exclude_DF$luck_vas_combined <- 3 - exclude_DF$luck_vas_combined

# for luck analyses people should be excluded if they get the answer wrong 
exclude_DF$luck_correct <- FALSE

exclude_DF$ri_wr <- factor(exclude_DF$ri_wr, 
                           levels = c(1,2),
                           labels = c("Right", "Wrong"))
exclude_DF$luck_correct[exclude_DF$cond == "Ignorance" & exclude_DF$ri_wr == "Wrong"] <- TRUE
exclude_DF$luck_correct[exclude_DF$cond != "Ignorance" & exclude_DF$ri_wr == "Right"] <- TRUE

table(exclude_DF$luck_correct)

# fix other variables
exclude_DF$gender2 <- factor(exclude_DF$gender,
                             levels = c("female", "male"))

# subset the wrong answers 
exclude_luck <- subset(exclude_DF, luck_correct)
```

## Knowledge

### Condition

- Results from coefficients are within a confidence interval of each other. 

<details><summary>View full results</summary>

```{r}
exclude_DF$know_vas_combined <- exclude_DF$know_vas_combined - 1
k.cond.exclude <- glmer(know_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond,
                      data = exclude_DF,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(k.cond.exclude)

summary(log_exclude[[6]])
```

</details>

### Vignette

- Results from coefficients are within a confidence interval of each other. 

<details><summary>View full results</summary>

```{r}
k.vignette.exclude <- glmer(know_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*vignette,
                      data = exclude_DF,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(k.vignette.exclude)

summary(log_exclude[[7]])
```

</details>

### Turk

- Results from coefficients are within a confidence interval of each other. The significance level changes for the Turk analysis, however, this is likely due to power, as there are more participants in this analysis. 
- The pattern of data suggests the same results, with more selection of believes in the ignorance condition. 

<details><summary>View full results</summary>

```{r}
k.turk.exclude <- glmer(know_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*turk,
                      data = exclude_DF,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(k.turk.exclude)

summary(log_exclude[[8]])

data_graph <- k.turk.exclude@frame
data_graph$know_vas_combined <- factor(data_graph$know_vas_combined,
                                          levels = c(0,1),
                                          labels = c("Believes", "Knows"))

#graph the three way binary 
ggplot(data_graph) +
  geom_mosaic(aes(x = product(know_vas_combined, cond, turk), 
                  fill = know_vas_combined), color = "black", size = .5) + 
  scale_fill_brewer(palette = "Greys", name = "Knowledge Choice", 
                    direction = -1) + 
  theme(text = element_text(size = 15)) + 
  scale_x_productlist(breaks = c(.5,.95),
   labels = c("College", "MTurk")) + 
  theme_classic() + 
  xlab("Turk") + 
  ylab("Condition")
```

</details>

## Reasonable

### Condition

- Results from coefficients are within a confidence interval of each other. 

<details><summary>View full results</summary>

```{r}
exclude_DF$reason_vas_combined <- exclude_DF$reason_vas_combined - 1
r.cond.exclude <- glmer(reason_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond,
                      data = exclude_DF,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(r.cond.exclude)

summary(log_exclude[[14]])
```

</details>

### Vignette

- Results from coefficients are within a confidence interval of each other. 

<details><summary>View full results</summary>

```{r}
r.vignette.exclude <- glmer(reason_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*vignette,
                      data = exclude_DF,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(r.vignette.exclude)

summary(log_exclude[[15]])
```

</details>

### Turk

- Results from coefficients are within a confidence interval of each other. The significance level changes for the Turk analysis, however, this is likely due to power, as there are more participants in this analysis. 
- This pattern of results indicates the same results as other samples - very few people pick unreasonable overall with slightly more in the ignorance category. 

<details><summary>View full results</summary>

```{r}
r.turk.exclude <- glmer(reason_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*turk,
                      data = exclude_DF,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(r.turk.exclude)

summary(log_exclude[[16]])

data_graph <- r.turk.exclude@frame
data_graph$reason_vas_combined <- factor(data_graph$reason_vas_combined,
                                          levels = c(0,1),
                                          labels = c("Unreasonable", "Reasonable"))

#graph the three way binary 
ggplot(data_graph) +
  geom_mosaic(aes(x = product(reason_vas_combined, cond, turk), 
                  fill = reason_vas_combined), color = "black", size = .5) + 
  scale_fill_brewer(palette = "Greys", name = "Reason Choice", 
                    direction = -1) + 
  theme(text = element_text(size = 15)) + 
  scale_x_productlist(breaks = c(.5,.95),
   labels = c("College", "MTurk")) + 
  theme_classic() + 
  xlab("Turk") + 
  ylab("Condition")
```

</details>

## Luck 

### Condition 

- Results from coefficients are within a confidence interval of each other.

<details><summary>View full results</summary>

```{r}
exclude_luck$luck_vas_combined <- exclude_luck$luck_vas_combined - 1
l.cond.exclude <- glmer(luck_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond,
                      data = exclude_luck,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(l.cond.exclude)

summary(log_exclude[[22]])
```

</details>

### Vignette

- Results from coefficients are within a confidence interval of each other.

<details><summary>View full results</summary>

```{r}
l.vignette.exclude <- glmer(luck_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*vignette,
                      data = exclude_luck,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(l.vignette.exclude)

summary(log_exclude[[23]])
```

</details>

### Turk

- Results from coefficients are within a confidence interval of each other.

<details><summary>View full results</summary>

```{r}
l.turk.exclude <- glmer(luck_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*turk,
                      data = exclude_luck,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(l.turk.exclude)

summary(log_exclude[[24]])
```

</details>






# Just Emma or Gerald

- This second covers the "Direct" replication analysis on just Emma and just Gerald, given they correctly answered the question for that vignette correctly (the scoring for correct is presented earlier in this document). 

```{r}
# data prep
exclude_DF <- full_long %>% 
  filter(correct == TRUE) 

# knowledge recode
exclude_DF$know_vas_binned <- exclude_DF$know_vas
exclude_DF$know_vas_binned[exclude_DF$know_vas_binned <= 40] <- 2
exclude_DF$know_vas_binned[exclude_DF$know_vas_binned > 40 & 
                             exclude_DF$know_vas_binned < 60] <- NA
exclude_DF$know_vas_binned[exclude_DF$know_vas_binned >= 60] <- 1
exclude_DF$know_vas_combined <- ifelse(is.na(exclude_DF$know_vas_binned), 
                                     exclude_DF$know_bin, 
                                     exclude_DF$know_vas_binned)

exclude_DF$know_vas_combined <- 3 - exclude_DF$know_vas_combined

# fix other variables
exclude_DF$gender2 <- factor(exclude_DF$gender,
                             levels = c("female", "male"))

# gerald
gerald_DF <- exclude_DF %>% 
  filter(vignette_order == "GED" | vignette_order == "GDE") %>% 
  filter(vignette == "Gerald")
nrow(gerald_DF)

# emma
emma_DF <- exclude_DF %>% 
  filter(vignette_order == "EDG" | vignette_order == "EGD") %>% 
  filter(vignette == "Emma")
nrow(emma_DF)
```

## Gerald 

- Overall chi-square is significant with a similar effect size to Darrel only. 
- Gettier versus Ignorance shows the same effect size and pattern of effects. 
- Gettier versus Knowledge shows the same effect size and pattern of effects. 
<details><summary>View full results</summary>

```{r}
gerald_only <- chisq.test(gerald_DF$cond, gerald_DF$know_vas_combined)
MOTE_gerald <- v.chi.sq(
  x2 = gerald_only$statistic,
  n = sum(gerald_only$observed),
  r = 2,
  c = 3,
  a = .05
)

gerald_only
MOTE_gerald

k.g_table_rep <- table(gerald_DF$know_vas_combined, gerald_DF$cond)
k.g_table_rep

k.gcond_GI_rep <- prop.test(t(k.g_table_rep[2:1, 1:2])) %>% 
  tidy()
k.gcond_GI_rep

k.gcond_GI_v_rep <- v.chi.sq(x2 = prop.test(t(k.g_table_rep[2:1, 1:2]))$statistic, 
         n = sum(t(k.g_table_rep[2:1, 1:2])),
         r = 2, c = 2) 
k.gcond_GI_v_rep

k.gcond_GK_rep <- prop.test(t(k.g_table_rep[2:1, c(1,3)])) %>% 
  tidy()
k.gcond_GK_rep

k.gcond_GK_v_rep <- v.chi.sq(x2 = prop.test(t(k.g_table_rep[2:1, c(1,3)]))$statistic, 
         n = sum(t(k.g_table_rep[2:1, c(1,3)])),
         r = 2, c = 2) 
k.gcond_GK_v_rep

k.gcond_GI_rep$estimate1
k.gcond_GI_rep$estimate2
k.gcond_GK_rep$estimate1
k.gcond_GK_rep$estimate2
```

</details>

## Emma

- Overall chi-square is significant with a smaller effect size than Darrel or Gerald. 
- Gettier versus Ignorance shows the same pattern of effects with approximately half of the effect size. 
- Gettier versus Knowledge shows the same pattern of effects with approximately half of the effect size. 


<details><summary>View full results</summary>

```{r}
emma_only <- chisq.test(emma_DF$cond, emma_DF$know_vas_combined)
MOTE_emma <- v.chi.sq(
  x2 = emma_only$statistic,
  n = sum(emma_only$observed),
  r = 2,
  c = 3,
  a = .05
)

emma_only
MOTE_emma

k.e_table_rep <- table(emma_DF$know_vas_combined, emma_DF$cond)
k.e_table_rep

k.econd_GI_rep <- prop.test(t(k.e_table_rep[2:1, 1:2])) %>% 
  tidy()
k.econd_GI_rep

k.econd_GI_v_rep <- v.chi.sq(x2 = prop.test(t(k.e_table_rep[2:1, 1:2]))$statistic, 
         n = sum(t(k.e_table_rep[2:1, 1:2])),
         r = 2, c = 2) 
k.econd_GI_v_rep

k.econd_GK_rep <- prop.test(t(k.e_table_rep[2:1, c(1,3)])) %>% 
  tidy()
k.econd_GK_rep

k.econd_GK_v_rep <- v.chi.sq(x2 = prop.test(t(k.e_table_rep[2:1, c(1,3)]))$statistic, 
         n = sum(t(k.e_table_rep[2:1, c(1,3)])),
         r = 2, c = 2) 
k.econd_GK_v_rep

k.econd_GI_rep$estimate1
k.econd_GI_rep$estimate2
k.econd_GK_rep$estimate1
k.econd_GK_rep$estimate2
```

</details>

# Update Table 6/Figure 3

```{r}
log_exclude[[7]]@frame %>% 
  mutate(know_vas_combined = factor(know_vas_combined, 
                                    levels = c(0,1), 
                                    labels = c("Believes", "Knows"))) %>% 
  group_by(know_vas_combined, cond, vignette) %>% 
  summarize(frequency = n()) %>% 
  arrange(desc(cond)) %>% 
  pivot_wider(id_cols = c(know_vas_combined, vignette), names_from = cond, values_from = frequency) %>% 
  ungroup() 
```

# Just a Midpoint Split

- The first results presented in each section represent the midpoint split, while the second results indicate the information presented in the manuscript. 

```{r}
# data prep
exclude_DF <- full_long %>% 
  filter(total_exclusion < 1)

# knowledge recode
exclude_DF$know_vas_binned <- exclude_DF$know_vas
exclude_DF$know_vas_binned[exclude_DF$know_vas_binned <= 50] <- 2
exclude_DF$know_vas_binned[exclude_DF$know_vas_binned >= 50] <- 1
exclude_DF$know_vas_combined <- ifelse(is.na(exclude_DF$know_vas_binned), 
                                     exclude_DF$know_bin, 
                                     exclude_DF$know_vas_binned)

exclude_DF$know_vas_combined <- 3 - exclude_DF$know_vas_combined

# reason recode
exclude_DF$reason_vas_binned <- exclude_DF$reason_vas
exclude_DF$reason_vas_binned[exclude_DF$reason_vas_binned <= 50] <- 2
exclude_DF$reason_vas_binned[exclude_DF$reason_vas_binned >= 50] <- 1
exclude_DF$reason_vas_combined <- ifelse(is.na(exclude_DF$reason_vas_binned), 
                                     exclude_DF$reason_bin, 
                                     exclude_DF$reason_vas_binned)

exclude_DF$reason_vas_combined <- 3 - exclude_DF$reason_vas_combined

# luck recode
exclude_DF$luck_vas_binned <- exclude_DF$luck_vas
exclude_DF$luck_vas_binned[exclude_DF$luck_vas_binned <= 50] <- 2
exclude_DF$luck_vas_binned[exclude_DF$luck_vas_binned >= 50] <- 1
exclude_DF$luck_vas_combined <- ifelse(is.na(exclude_DF$luck_vas_binned), 
                                     exclude_DF$luck_bin, 
                                     exclude_DF$luck_vas_binned)

exclude_DF$luck_vas_combined <- 3 - exclude_DF$luck_vas_combined

# for luck analyses people should be excluded if they get the answer wrong 
exclude_DF$luck_correct <- FALSE

exclude_DF$ri_wr <- factor(exclude_DF$ri_wr, 
                           levels = c(1,2),
                           labels = c("Right", "Wrong"))
exclude_DF$luck_correct[exclude_DF$cond == "Ignorance" & exclude_DF$ri_wr == "Wrong"] <- TRUE
exclude_DF$luck_correct[exclude_DF$cond != "Ignorance" & exclude_DF$ri_wr == "Right"] <- TRUE

table(exclude_DF$luck_correct)

# fix other variables
exclude_DF$gender2 <- factor(exclude_DF$gender,
                             levels = c("female", "male"))

# subset the wrong answers 
exclude_luck <- subset(exclude_DF, luck_correct)
```

## Knowledge

### Condition

- Results from coefficients are within a confidence interval of each other. 

<details><summary>View full results</summary>

```{r}
exclude_DF$know_vas_combined <- exclude_DF$know_vas_combined - 1
k.cond.exclude <- glmer(know_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond,
                      data = exclude_DF,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(k.cond.exclude)

summary(log_exclude[[6]])
```

</details>

### Vignette

- Results from coefficients are within a confidence interval of each other. 

<details><summary>View full results</summary>

```{r}
k.vignette.exclude <- glmer(know_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*vignette,
                      data = exclude_DF,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(k.vignette.exclude)

summary(log_exclude[[7]])
```

</details>

### Turk

- Results from coefficients are within a confidence interval of each other. 

<details><summary>View full results</summary>

```{r}
k.turk.exclude <- glmer(know_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*turk,
                      data = exclude_DF,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(k.turk.exclude)

summary(log_exclude[[8]])
```

</details>

## Reasonable

### Condition

- Results from coefficients are within a confidence interval of each other. 

<details><summary>View full results</summary>

```{r}
exclude_DF$reason_vas_combined <- exclude_DF$reason_vas_combined - 1
r.cond.exclude <- glmer(reason_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond,
                      data = exclude_DF,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(r.cond.exclude)

summary(log_exclude[[14]])
```

</details>

### Vignette

- Results from coefficients are within a confidence interval of each other. 

<details><summary>View full results</summary>

```{r}
r.vignette.exclude <- glmer(reason_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*vignette,
                      data = exclude_DF,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(r.vignette.exclude)

summary(log_exclude[[15]])
```

</details>

### Turk

- Results from coefficients are within a confidence interval of each other. 

<details><summary>View full results</summary>

```{r}
r.turk.exclude <- glmer(reason_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*turk,
                      data = exclude_DF,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(r.turk.exclude)

summary(log_exclude[[16]])
```

</details>

## Luck 

### Condition 

- Results from coefficients are within a confidence interval of each other.

<details><summary>View full results</summary>

```{r}
exclude_luck$luck_vas_combined <- exclude_luck$luck_vas_combined - 1
l.cond.exclude <- glmer(luck_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond,
                      data = exclude_luck,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(l.cond.exclude)

summary(log_exclude[[22]])
```

</details>

### Vignette

- Results from coefficients are within a confidence interval of each other.

<details><summary>View full results</summary>

```{r}
l.vignette.exclude <- glmer(luck_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*vignette,
                      data = exclude_luck,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(l.vignette.exclude)

summary(log_exclude[[23]])
```

</details>

### Turk

- Results from coefficients are within a confidence interval of each other.

<details><summary>View full results</summary>

```{r}
l.turk.exclude <- glmer(luck_vas_combined ~ (1|vignette/id/person_code) + 
                    comp + age + gender2 + education + 
                    cond*turk,
                      data = exclude_luck,
                      family = binomial,
                      control = glmerControl(optimizer = "bobyqa"),
                      nAGQ = 0)

summary(l.turk.exclude)

summary(log_exclude[[24]])
```

</details>

# Graph of Area Representation

```{r}
# convert country code to region code
# this will warn you about the ones that have multiple countries 
# create a world map 
world_map <- map_data(map = "world")
world_map$orig_region <- world_map$region
world_map$region <- iso.alpha(world_map$region, n = 3)
world_map <- subset(world_map, region != "ATA")

# summarize the same samples
country_summary <- full_long %>% 
      filter(!duplicated(full_long %>% select(id))) %>% 
      group_by(lab_country) %>% 
      summarize(n = n()) %>% 
      filter(!is.na(lab_country))

# make a map on a continuous scale
ggplot(country_summary) +
  geom_map(aes(map_id = lab_country, fill = n), map = world_map) +
  geom_polygon(data = world_map, 
               aes(x = long, y = lat, group = group), 
               colour = 'black', fill = NA) + 
  theme_void() + 
  scale_fill_distiller(name = "Sample Size",
                       palette = "Greys",
                       direction = 1,
                       na.value = "white") 

ggsave("figure/continuous_country.png")
  
# maybe try binning
country_summary$n_binned <- if_else(
  country_summary$n > 1000, "1000+", 
  if_else(
    country_summary$n < 1000 & country_summary$n >= 400, "400-999", 
    if_else(
      country_summary$n < 400 & country_summary$n >= 100, "100-399", 
      "< 100"
    )
  )
)

# map of binned data 
bin_country <- ggplot(country_summary) +
  geom_map(aes(map_id = lab_country, fill = n_binned), map = world_map) +
  geom_polygon(data = world_map, 
               aes(x = long, y = lat, group = group), 
               colour = 'black', fill = NA) + 
  theme_void() + 
  scale_fill_manual(name = "Sample Size",
                    values = c("#c8c8c8", "#969696", "#646464", "#323232")) 

bin_country

ggsave("figure/binned_country.png", bin_country)

# tree map
country_summary$un_region_sub <- countrycode(
  sourcevar = country_summary$lab_country,
  origin = 'iso3c', 
  destination = 'un.regionsub.name'
)

country_summary$un_region <- countrycode(
  sourcevar = country_summary$lab_country,
  origin = 'iso3c', 
  destination = 'un.region.name'
)

country_summary$un_region[is.na(country_summary$un_region)] <- "Asia"
country_summary$un_region_sub[is.na(country_summary$un_region_sub)] <- "Eastern Asia"

tree <- ggplot(country_summary, aes(area = n, fill = n_binned,
               label = lab_country, subgroup = un_region_sub)) +
  geom_treemap() +
  geom_treemap_subgroup_border(colour = "white", size = 5) +
  # geom_treemap_subgroup_text(place = "top", grow = TRUE,
  #                            alpha = 0.25, colour = "black",
  #                            fontface = "italic") +
  geom_treemap_text(colour = "white", place = "centre",
                    size = 15, grow = FALSE) +  
  scale_fill_manual(name = "Sample Size",
                    values = c("#c8c8c8", "#969696", "#646464", "#323232")) 
  # scale_fill_gradient(name = "Sample Size",
  #                     low = "#c8c8c8", 
  #                     high = "#323232") 

tree 

ggsave("figure/treemap.png",
       tree)
```

# Forest Plot of Effects

## Knowledge

```{r}
table(final_long$lab_country, useNA = "ifany")
unique_country <- unique(final_long$lab_country)

country_results <- list()
for (i in unique_country){
  
  temp_data <- final_long %>% 
    filter(lab_country == i)
  
  k_table <- table(temp_data$know_vas_combined, temp_data$cond)
  
  tryCatch(k_GI <- v.chi.sq(x2 = prop.test(t(k_table[2:1, 1:2]))$statistic, 
         n = sum(t(k_table[2:1, 1:2])),
         r = 2, c = 2), 
         warning = function(w) { 
      k_GI <<- v.chi.sq(x2 = prop.test(t(k_table[2:1, 1:2]))$statistic, 
         n = sum(t(k_table[2:1, 1:2])),
         r = 2, c = 2)
      k_GI$vlow <<- 0
    }
  )
  
  tryCatch(  k_GK <- v.chi.sq(x2 = prop.test(t(k_table[2:1, c(1,3)]))$statistic, 
         n = sum(t(k_table[2:1, c(1,3)])),
         r = 2, c = 2), 
         warning = function(w) { 
      k_GK <<- v.chi.sq(x2 = prop.test(t(k_table[2:1, c(1,3)]))$statistic, 
         n = sum(t(k_table[2:1, c(1,3)])),
         r = 2, c = 2)
      k_GK$vlow <<- 0
    }
  )
  
  country_results[[i]]$country <- i
  country_results[[i]]$GI <- k_GI$v
  country_results[[i]]$GI_low <- k_GI$vlow
  country_results[[i]]$GI_high <- k_GI$vhigh
  country_results[[i]]$GK <- k_GK$v
  country_results[[i]]$GK_low <- k_GK$vlow
  country_results[[i]]$GK_high <- k_GK$vhigh
  country_results[[i]]$sample <- nrow(temp_data)
  
}

country_DF <- bind_rows(country_results)

ggplot(country_DF, aes(country, GI)) + 
  theme_classic() + 
  geom_point(aes(size = sample)) + 
  geom_errorbar(aes(ymin = GI_low, ymax = GI_high)) + 
  ylab("Knowledge Cramer's V for Gettier-Ignorance") + 
  xlab("Geopolitical Region") + 
  coord_flip() + 
  theme(legend.position = "none")


ggplot(country_DF, aes(country, GK)) + 
  theme_classic() + 
  geom_point(aes(size = sample)) + 
  geom_errorbar(aes(ymin = GK_low, ymax = GK_high)) + 
  ylab("Knowledge Cramer's V for Gettier-Knowledge") + 
  xlab("Geopolitical Region") + 
  coord_flip() + 
  theme(legend.position = "none")

```

