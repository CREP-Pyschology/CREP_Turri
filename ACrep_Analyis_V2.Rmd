---
title: "ACREP Updated Analyses"
author: "erin buchanan"
date: "Last Updated `r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Information

Multilab close replication of: Experiment 1 from Turri, J., Buckwalter, W., & Blouw, P. (2015). Knowledge and luck. *Psychonomic Bulletin and Review*, 22, 378-390.

[Data and registered protocols:](https://osf.io/n5b3w/)

[Codebook](https://docs.google.com/spreadsheets/d/1KjXqgfVgguHeDXVtlHHhJ9zsRGVDfPVPH4tbh75P46U/edit#gid=903093128)

[Preprint](https://psyarxiv.com/zeux9/)

## Libraries

```{r}
library(rio)
library(nlme)
library(MuMIn)
library(plyr)
library(psych)
```

## Import the Data

The `full_long` dataset includes all participants in long format - wherein each trial of their study is on one row of the dataset. Our uploaded data also includes `full.Rds` which is the same data in wide format - one column for each variable in the dataset and one row per participant.

```{r}
full_long <- readRDS("./04_Data/rds/d_all_long.Rds")
#str(full_long)
```

Import the open-ended response codes to use for data exclusions.

```{r}
file.names <- list.files(path = "./04_Data/open_responses/", 
                         pattern = ".xlsx", full.names = T, 
                         recursive = T)

previous.files <- lapply(file.names, function(x){ import(x, sheet = 2)})
purpose.files <- lapply(file.names, function(x){ import(x, sheet = 3)})

previousDF <- do.call(rbind.fill, previous.files)
purposeDF <- do.call(rbind.fill, purpose.files)

# long to wide for scoring

# fix the yes/no/maybe/NA

# score the yes/no/maybe/NA
```

## Fix Data Coding / Examine Covariates  

```{r}
# make empty vignettes NA to exclude
# drop empty levels 
full_long$vignette_order[full_long$vignette_order == ""] <- NA
full_long$vignette_order <- droplevels(full_long$vignette_order) 
levels(full_long$vignette_order)

# give compensation type labels 
full_long$comp_type <- factor(full_long$comp_type, 
                              levels = 1:4,
                              labels = c("Credit", "Gift Card", "Money", "Other"))

# how many of each compensation type 
table(full_long$comp_type) / 3 #three rows for each person 

# how many of each gender
table(full_long$gender) / 3

# describe education years
full_long$education <- as.numeric(full_long$education)
describe(full_long$education[!duplicated(full_long$id)])

# age is described below 
```

  (1) if the participant is not the majority age of their country or older (unless parent/guardian waiver provided)

In this section, we will exclude all participants who are under 18 or are not the majority age of their country or older.

https://en.wikipedia.org/wiki/Age_of_majority

```{r}
# table of lab countries
table(full_long$lab_country, useNA = "ifany")

# age information
summary(full_long$age)

# minimum age by country
tapply(full_long$age, full_long$lab_country, min, na.rm = T)

# number of rows
nrow(full_long)
# number of participants
length(unique(full_long$id))

# exclude based on age
full_long$age_exclusion <- NA

age18 <- c("AUT", "AUS", "CAN", "CHE", "DEU", "GBR", "GRC", "HUN", "NOR", "NZL", "POL", "PRT", "ROU", "RUS", "SGP", "TUR", "TWN", "USA")
age19 <- c("SVK")
age21 <- c("ARE")

full_long$age_exclusion[full_long$lab_country %in% age18] <- full_long$age[full_long$lab_country %in% age18] < 18

full_long$age_exclusion[full_long$lab_country %in% age19] <- full_long$age[full_long$lab_country %in% age19] < 19

full_long$age_exclusion[full_long$lab_country %in% age21] <- full_long$age[full_long$lab_country %in% age21] < 21

full_long$age_exclusion[is.na(full_long$age_exclusion)] <- TRUE

full_long$age_exclusion[full_long$age > 100] <- TRUE
```

(2) if the participant has taken part in a previous version of this study or in another contributors' replication of the same study

```{r}
# pull in dictionary 
previousDF$code <- as.character(tolower(previousDF$code))
previousDF$code[previousDF$code == "n/a"] <- "na"
table(previousDF$code)

# coding scheme
previousDF$total <- 0
# previousDF$total[previousDF$code == "yes"] <- previousDF$total[previousDF$code == "yes"] + 2
# previousDF$total[previousDF$code == "na"] <- previousDF$total[previousDF$code == "na"] + 4
# previousDF$total[previousDF$code == "test"] <- previousDF$total[previousDF$code == "test"] + 4

## maybe gets 1 point 
## cut off is four points 
## na gets zero points 
## mark nonsense responses if they are all NA 
```

(3) if the participant fails to answer comprehension questions correctly

```{r}
full_long$studyans_exclusion <- full_long$dge_valid == FALSE
```

(4) if the participant correctly and explicitly articulate knowledge of the specific hypotheses or specific conditions of this study when answering the funneled debriefing questions. 

```{r}
# pull in dictionary 
# subset using dictionary 
full_long$knowledge_exclusion <- NA
```

We will also exclude participants who self-report their understanding of the tested language as "not well" or "not well at all". We based this exclusion criteria on a recent study that found that non-native English speakers who self-report as "very well" and "well" tend to score in the "intermediate" and "basic" categories on an English proficiency test respectively, while those who self-report as "not well" and "not at all" tend to score in the "below basic" category (Vickstrom, Shin, Collazo, & Bauman, 2015). All excluded data will be included in the data files on the overall OSF page, along with the particular reason for why they were excluded. 

```{r}
summary(full_long$language)

full_long$lang_exclusion <- full_long$language == "not very well" | full_long$language == "not well at all" 

full_long$lang_exclusion[is.na(full_long$lang_exclusion)] <- TRUE
```

```{r}
full_long$total_exclusion <- full_long$age_exclusion + full_long$studyans_exclusion + full_long$lang_exclusion #### ADD OTHER TWO

table(full_long$age_exclusion)
table(full_long$lang_exclusion)
table(full_long$studyans_exclusion)
table(full_long$total_exclusion)

final_long <- subset(full_long, total_exclusion < 1)

nrow(full_long)
nrow(final_long)

length(unique(full_long$id))
length(unique(final_long$id))
```

#### Analysis Information ####

- Drop the section on X did not collect enough data because we used all the data
- Change that to X did not get included because they didn't have enough valid data 
- Report full and final lab counts 

```{r}
# total lab count
length(unique(full_long$lab_id))

# usable data lab count
length(unique(final_long$lab_id))

# total countries
table(full_long$lab_country)
length(table(full_long$lab_country))

# usable countries
table(final_long$lab_country)
length(table(final_long$lab_country))
```



- Control variables include:
  - Language proficiency
  - Debriefing knowledge questions
  - While these are labeled as "control", these variables are used as ways to exclude participants. This section should be relabeled as exclusionary variables. 
  
- Covariates:
  - All demographic and other variables measured at each site included in all data - this sentence should be removed it is completely unclear 
  - Test setting: online versus face to face - this section should be modified since no labs were in person 
  - Test setting: individually versus group - this section should be modified since all was online
  - Test setting: compensated versus uncompensated
  - Age
  - Gender (men/women/other)
  - Years of education 
  
  
- We will do both logistic regression (binary outcome) and regression (visual analogue outcome)
- We will use multilevel modeling 
  - The condition will be a random intercept
  - The participants will be a random intercept 
- The independent variable will be the knowledge condition 

#### Analysis Information ####

- See number above for total number of labs
- Remember we did not include several labs for qualtrics issues
- Just delete this MLM section for being repetative and slightly incorrect 

#### Analysis Information ####

- I think this section can go, it should be listed in credit who did what here
- Call things random and fixed factors
- No real need to label within and between as it appears to be confusing with the random / fixed terminology 
- Here you really say the analyses are: 
  - Gender
  - Education
  - Age
  - The test settings, which two are dropped, we are left with compensation only 
- Definitely remove that sentence earlier so these match 
- Exploratory variables:
  - Individual, lab, and stimulus differences (i.e., look at their R2 values, make some cool pictures? can use random intercepts for this)


#### Analysis Information ####

- Country is a tricky word - remember to change it to something like country or geographic region 
- Assumptions:
  - Linearity for VAS - clarify this here
  - know reason and luck 

--- need to do the UN country coding to add to this 
--- man this data screening is bad 

```{r}
# drop levels
final_long$lab_id <- droplevels(final_long$lab_id)
final_long$id <- factor(final_long$id)
final_long$vignette <- factor(final_long$vignette)

# we do data screening on the final model 
# dv is know, reason, luck by vas/bin
# really just need to check vas because binary doesn't have the same assumptions
# iv is condition 
# cv is test setting, age, gender, years education
```

```{r}
## knowledge 
ds.model <- lme(know_vas ~ cond + comp_type + age + gender + education ,
                random = list(~1|vignette, ~1|id, ~1|lab_id),
                data = final_long,
                na.action = "na.omit")

# additivity
round(summary(ds.model)$corFixed,2)

# normality
standardized <- residuals(ds.model, type = "normalized")
hist(standardized) # just further evidence these distributions are bimodal 
# linearity
{qqnorm(standardized)
  abline(0,1)}

# homosc
fitted <- scale(fitted.values(ds.model))
{plot(fitted, standardized)
  abline(v = 0)
  abline(h = 0)}
```

```{r}
## reasonable 
ds.model <- lme(reason_vas ~ cond + comp_type + age + 
                  gender + education ,
                random = list(~1|vignette, ~1|id, ~1|lab_id),
                data = final_long,
                na.action = "na.omit")

# additivity
round(summary(ds.model)$corFixed,2)

# normality
standardized <- residuals(ds.model, type = "normalized")
hist(standardized) 

# linearity
{qqnorm(standardized)
  abline(0,1)}

# homosc
fitted <- scale(fitted.values(ds.model))
{plot(fitted, standardized)
  abline(v = 0)
  abline(h = 0)}
```

```{r}
## luck 
ds.model <- lme(luck_vas ~ cond + comp_type + age + 
                  gender + education ,
                random = list(~1|vignette, ~1|id, ~1|lab_id),
                data = final_long,
                na.action = "na.omit")

# additivity
round(summary(ds.model)$corFixed,2)

# normality
standardized <- residuals(ds.model, type = "normalized")
hist(standardized) 

# linearity
{qqnorm(standardized)
  abline(0,1)}

# homosc
fitted <- scale(fitted.values(ds.model))
{plot(fitted, standardized)
  abline(v = 0)
  abline(h = 0)}
```

#### Analysis Information ####

- Here let's regroup by testing the random effects first because I don't know that I  think the fixed effects mean anything without controlling for correlated error first
- Definitely don't use null model this way, that's not what that means (usually null model regressions are NO predictors at all)
- Also here, belief condition can't just be one B value - it will be two since it's a categorical variable with three levels (a versus b, b versus c)


#### Analysis Information ####

- Ditch ICC here, instead let's use MuMIn's R2 for random effects
- Another reason to start with a blank model and add these first
- Otherwise condition is in the way here and you don't know this answer
- I kind of get what you are going for here but I don't think by including condition then adding the random factors you answer this question of "does belief change by person/vignette/lab". That's basically asking for the interaction. You could reword this as "is knowledge attribution variable by person/vignette/lab" and after you account for that, does condition predict the dv? 
- I'd rewrite this section to be: 
  - We start with level 1 
  - Then we add level 2 
  - Then we add level 3
  - Then covariates 
  - Then we add main variable
  - Then random lab slope

- Get rid of these several paragraph below 
- Not sure I would talk about reliability with ICCs, but we can do correlations between vignettes 

```{r}
# level 1
# level 2
# level 3
# covariates
# condition 

# correlation vignettes 
```

#### Analysis Information ####

- I'm really not sure what you are saying below 
- What is the cross level interaction? What variables are interacting? 
- Is it both condition and lab as random slopes?

#### Analysis Information ####

- Also not sure what you are saying here below 
- How are you correcting this? Like what are we correcting? The model coefficient values? Or just some correlations? 

#### Analysis Information #### 

- Let's not mix covariate terminology with covariance structure terminology here. 
- Is there a good reason to use these different matrices? (I haven't seen it this way much but doesn't mean it's wrong) 

```{r}
ds.model <- lme(know_vas ~ 1,
                random = list(~1|vignette),
                data = final_long,
                na.action = "na.omit")
summary(ds.model)
r.squaredGLMM(ds.model)

ds.model <- lme(know_vas ~ 1,
                random = list(~1|id),
                data = final_long,
                na.action = "na.omit")
summary(ds.model)
r.squaredGLMM(ds.model)

ds.model <- lme(know_vas ~ 1,
                random = list(~1|lab_id),
                data = final_long,
                na.action = "na.omit")
summary(ds.model)
r.squaredGLMM(ds.model)

ds.model <- lme(know_vas ~ 1,
                random = list(~1|vignette, ~1|id, ~1|lab_id),
                data = final_long,
                na.action = "na.omit")
summary(ds.model)
r.squaredGLMM(ds.model)
```

  